{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['potential_energy.csv', 'mulliken_charges.csv', 'train.csv', 'scalar_coupling_contributions.csv', 'sample_submission.csv', 'structures', 'test.csv', 'magnetic_shielding_tensors.csv', 'dipole_moments.csv', 'structures.csv']\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n",
    "from sklearn import linear_model\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import os\n",
    "print(os.listdir(\"../input\"))\n",
    "\n",
    "# Any results you write to the current directory are saved as output."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load all the data into a single dataframe. Use one hot encoding for he atom types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "le = LabelEncoder()\n",
    "oh = OneHotEncoder(sparse = False)\n",
    "df = pd.read_csv('../input/train.csv',sep=',', header=0, usecols=['molecule_name','atom_index_0','atom_index_1','type','scalar_coupling_constant'] )\n",
    "df_m_coupling_contributions = pd.read_csv('../input/scalar_coupling_contributions.csv',\n",
    "                       sep=',', header=0, usecols=['molecule_name','atom_index_0','atom_index_1','fc','sd','pso', 'dso'])\n",
    "df = pd.merge(df, df_m_coupling_contributions, on=['molecule_name','atom_index_0','atom_index_1'])\n",
    "df_m_diple_moments = pd.read_csv('../input/dipole_moments.csv',sep=',', header=0, usecols=['molecule_name','X','Y','Z'])\n",
    "df = pd.merge(df, df_m_diple_moments, on='molecule_name')\n",
    "df_m_pot_engy = pd.read_csv('../input/potential_energy.csv',sep=',', header=0, usecols=['molecule_name','potential_energy'])\n",
    "df = pd.merge(df, df_m_pot_engy, on='molecule_name')\n",
    "\n",
    "df_a_str = pd.read_csv('../input/structures.csv',\n",
    "                       sep=',', header=0, usecols=['molecule_name','atom_index','atom','x','y','z'])\n",
    "#df_a_str['atom'] = le.fit_transform(df_a_str['atom'])\n",
    "f = df_a_str['atom'].values\n",
    "f = np.reshape(f, (-1,1))\n",
    "f = oh.fit_transform(f)\n",
    "ohdf = pd.DataFrame(f)\n",
    "df_a_str = pd.concat([df_a_str, ohdf], axis=1)\n",
    "df_a_str = df_a_str.rename(index=str, columns={0: 'A0',1:'A1',2:'A2',3:'A3',4:'A4'})\n",
    "df_a_str.drop(columns=['atom'], inplace = True)\n",
    "df_a_mag_sh_tensor = pd.read_csv('../input/magnetic_shielding_tensors.csv',\n",
    "                       sep=',', header=0, usecols=['molecule_name','atom_index','XX','YX','ZX','XY','YY','ZY','XZ','YZ','ZZ'])\n",
    "\n",
    "df_a_mlkn_charges = pd.read_csv('../input/mulliken_charges.csv',sep=',', header=0, usecols=['molecule_name','atom_index','mulliken_charge'])\n",
    "\n",
    "df_a_str = pd.merge(df_a_str, df_a_mag_sh_tensor, on=['molecule_name','atom_index'])\n",
    "\n",
    "df_a_str = pd.merge(df_a_str, df_a_mlkn_charges, on=['molecule_name','atom_index'])\n",
    "\n",
    "df_atom_1_prop = df_a_str.rename(index=str, columns={'atom_index': 'atom_index_0','A0':'A0_0','A1':'A1_0','A2':'A2_0','A3':'A3_0','A4':'A4_0','x':'x_0','y':'y_0','z':'z_0', 'XX':'XX_0', 'YX':'YX_0', 'ZX':'ZX_0', 'XY':'XY_0', 'YY':'YY_0', 'ZY':'ZY_0', 'XZ':'XZ_0', 'YZ':'YZ_0', 'ZZ':'ZZ_0', 'mulliken_charge':'mulliken_charge_0'})\n",
    "df = pd.merge(df, df_atom_1_prop, on=['molecule_name','atom_index_0'])\n",
    "\n",
    "df_atom_2_prop = df_a_str.rename(index=str, columns={'atom_index': 'atom_index_1','A0':'A0_1','A1':'A1_1','A2':'A2_1','A3':'A3_1','A4':'A4_1','x':'x_1','y':'y_1','z':'z_1', 'XX':'XX_1', 'YX':'YX_1', 'ZX':'ZX_1', 'XY':'XY_1', 'YY':'YY_1', 'ZY':'ZY_1', 'XZ':'XZ_1', 'YZ':'YZ_1', 'ZZ':'ZZ_1', 'mulliken_charge':'mulliken_charge_1'})\n",
    "df = pd.merge(df, df_atom_2_prop, on=['molecule_name','atom_index_1'])\n",
    "ss = StandardScaler()\n",
    "df[['scalar_coupling_constant', 'fc', 'sd', 'pso', 'dso', 'X', 'Y', 'Z',\n",
    "       'potential_energy', 'x_0', 'y_0', 'z_0', 'A0_0', 'A1_0', 'A2_0', 'A3_0',\n",
    "       'A4_0', 'XX_0', 'YX_0', 'ZX_0', 'XY_0', 'YY_0', 'ZY_0', 'XZ_0', 'YZ_0',\n",
    "       'ZZ_0', 'mulliken_charge_0', 'x_1', 'y_1', 'z_1', 'A0_1', 'A1_1',\n",
    "       'A2_1', 'A3_1', 'A4_1', 'XX_1', 'YX_1', 'ZX_1', 'XY_1', 'YY_1', 'ZY_1',\n",
    "       'XZ_1', 'YZ_1', 'ZZ_1', 'mulliken_charge_1']] = ss.fit_transform(df[['scalar_coupling_constant', 'fc', 'sd', 'pso', 'dso', 'X', 'Y', 'Z',\n",
    "       'potential_energy', 'x_0', 'y_0', 'z_0', 'A0_0', 'A1_0', 'A2_0', 'A3_0',\n",
    "       'A4_0', 'XX_0', 'YX_0', 'ZX_0', 'XY_0', 'YY_0', 'ZY_0', 'XZ_0', 'YZ_0',\n",
    "       'ZZ_0', 'mulliken_charge_0', 'x_1', 'y_1', 'z_1', 'A0_1', 'A1_1',\n",
    "       'A2_1', 'A3_1', 'A4_1', 'XX_1', 'YX_1', 'ZX_1', 'XY_1', 'YY_1', 'ZY_1',\n",
    "       'XZ_1', 'YZ_1', 'ZZ_1', 'mulliken_charge_1']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A molecule has variable number of atom pairs. Each pair has a scalar coupling constant value. This function defines a (m x n x p) matrix for a molecule where m is the number of atom pair, n is 2, since its a pair, and p is the number of feature for each atom. \n",
    "A more sophisticated feature generation could help this model to be more accurate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_atom_pairs(name, molecule):\n",
    "    df = molecule.apply(list)\n",
    "    atom_pair_y = np.zeros((df.shape[0], 8))\n",
    "    \n",
    "    atom_pair = np.zeros((df.shape[0], 2, 18))\n",
    "    atom_pair[:,0,:] = df.as_matrix(columns=['x_0','y_0','z_0','XX_0','YX_0','ZX_0','XY_0',\n",
    "                                            'YY_0','ZY_0','XZ_0','YZ_0','ZZ_0','mulliken_charge_0',\n",
    "                                             'A0_0','A1_0','A2_0','A3_0','A4_0'])\n",
    "    atom_pair[:,1,:] = df.as_matrix(columns=['x_1','y_1','z_1','XX_1','YX_1','ZX_1','XY_1',\n",
    "                                            'YY_1','ZY_1','XZ_1','YZ_1','ZZ_1','mulliken_charge_1',\n",
    "                                             'A0_1','A1_1','A2_1','A3_1','A4_1'])\n",
    "   \n",
    "    atom_pair_y = df.as_matrix(columns=['potential_energy','X','Y','Z','fc','sd','pso','dso'])\n",
    "    return atom_pair, atom_pair_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "moleculelist = []\n",
    "molecule_ylist = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are unable to use the entire dataset, as kaggle has the memory limitation, so 10000 molecules are used to train the model. Bidirectional does not accept variable size input sequence, therefore each molecure is appened with 0 for upto 650 pairs of atoms.\n",
    "Using the entire training dataset will improve the performance of this model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:8: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  \n",
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:11: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:13: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  del sys.path[0]\n"
     ]
    }
   ],
   "source": [
    "molecules = df.groupby('molecule_name')\n",
    "c = 0\n",
    "for name, molecule in molecules:\n",
    "    atoms, molecule_y = build_atom_pairs(name, molecule)\n",
    "    amolecule = np.zeros((650,atoms.shape[1], atoms.shape[2]))\n",
    "    amolecule[:atoms.shape[0],:atoms.shape[1],:atoms.shape[2]] = atoms\n",
    "    amolecule = amolecule.transpose([0,2,1]).reshape(amolecule.shape[0], -1)\n",
    "    amolecule_y = np.zeros((650,molecule_y.shape[1]))\n",
    "    amolecule_y[:molecule_y.shape[0],:molecule_y.shape[1]] = molecule_y\n",
    "    moleculelist.append(amolecule)\n",
    "    molecule_ylist.append(amolecule_y)\n",
    "    c = c + 1\n",
    "    if c > 10000:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras import layers\n",
    "from keras.optimizers import Adam\n",
    "from keras.layers import Input, Dense, Activation, BatchNormalization, Flatten\n",
    "from keras.layers import Dropout\n",
    "from keras.models import Model\n",
    "from keras.preprocessing import image\n",
    "from keras.utils import layer_utils\n",
    "from keras.utils.data_utils import get_file\n",
    "from keras.applications.imagenet_utils import preprocess_input\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "from keras.utils import plot_model\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Bidirectional\n",
    "from keras.layers import LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model intend to use bidirectional RNN. This is because, if we consider a molecule M, containing p atoms in it, then each of pair combination has a scalar coupling constant and each pair within the molecule has an affect on each other's scalar couplingg constant value. So a bidirectional RNN, ensure that the affect of a pair is distributed among other pairs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def BRNNModel(inputdim):\n",
    "    model = Sequential()\n",
    "    model.add(Bidirectional(LSTM(100, return_sequences=True, input_dim= inputdim )))\n",
    "    #model.add(Bidirectional(LSTM(10)))\n",
    "    model.add(Dense(8))\n",
    "    model.add(Activation('relu'))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code is not used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_generator(X, y, batch_size):\n",
    "    number_of_batches = X.shape[0]/batch_size\n",
    "    counter=0\n",
    "    shuffle_index = np.arange(np.shape(y)[0])\n",
    "#    X =  X[shuffle_index, :]\n",
    "#    y =  y[shuffle_index]\n",
    "    while 1:\n",
    "        index_batch = shuffle_index[batch_size*counter:batch_size*(counter+1)]\n",
    "        X_batch = X[index_batch,:].todense()\n",
    "        y_batch = y[index_batch]\n",
    "        counter += 1\n",
    "        yield(np.array(X_batch),y_batch)\n",
    "        if (counter > number_of_batches):\n",
    "#            np.random.shuffle(shuffle_index)\n",
    "            counter=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.asarray(moleculelist)\n",
    "y = np.asarray(molecule_ylist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:3: UserWarning: The `input_dim` and `input_length` arguments in recurrent layers are deprecated. Use `input_shape` instead.\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:3: UserWarning: Update your `LSTM` call to the Keras 2 API: `LSTM(100, return_sequences=True, input_shape=(None, 650...)`\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "model = BRNNModel(X.shape[1])\n",
    "model.compile(optimizer = 'adam', loss = \"mean_squared_error\", metrics = [\"accuracy\"])#\"adam\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      " - 1066s - loss: 0.0621 - acc: 0.8759\n",
      "Epoch 2/30\n",
      " - 1056s - loss: 0.0558 - acc: 0.9559\n",
      "Epoch 3/30\n",
      " - 1039s - loss: 0.0515 - acc: 0.9685\n",
      "Epoch 4/30\n",
      " - 1028s - loss: 0.0487 - acc: 0.9720\n",
      "Epoch 5/30\n",
      " - 1021s - loss: 0.0469 - acc: 0.9729\n",
      "Epoch 6/30\n",
      " - 1017s - loss: 0.0458 - acc: 0.9737\n",
      "Epoch 7/30\n",
      " - 1013s - loss: 0.0444 - acc: 0.9744\n",
      "Epoch 8/30\n",
      " - 1018s - loss: 0.0434 - acc: 0.9750\n",
      "Epoch 9/30\n",
      " - 1046s - loss: 0.0426 - acc: 0.9757\n",
      "Epoch 10/30\n",
      " - 1029s - loss: 0.0419 - acc: 0.9762\n",
      "Epoch 11/30\n",
      " - 1023s - loss: 0.0414 - acc: 0.9766\n",
      "Epoch 12/30\n",
      " - 1010s - loss: 0.0409 - acc: 0.9772\n",
      "Epoch 13/30\n",
      " - 1003s - loss: 0.0404 - acc: 0.9774\n",
      "Epoch 14/30\n",
      " - 1059s - loss: 0.0399 - acc: 0.9780\n",
      "Epoch 15/30\n",
      " - 1062s - loss: 0.0414 - acc: 0.9753\n",
      "Epoch 16/30\n",
      " - 1061s - loss: 0.0399 - acc: 0.9783\n",
      "Epoch 17/30\n",
      " - 1193s - loss: 0.0391 - acc: 0.9788\n",
      "Epoch 18/30\n",
      " - 1089s - loss: 0.0385 - acc: 0.9795\n",
      "Epoch 19/30\n",
      " - 1063s - loss: 0.0384 - acc: 0.9795\n",
      "Epoch 20/30\n",
      " - 1062s - loss: 0.0378 - acc: 0.9802\n",
      "Epoch 21/30\n",
      " - 1064s - loss: 0.0374 - acc: 0.9805\n",
      "Epoch 22/30\n",
      " - 1065s - loss: 0.0371 - acc: 0.9807\n",
      "Epoch 23/30\n",
      " - 1064s - loss: 0.0368 - acc: 0.9811\n",
      "Epoch 24/30\n",
      " - 1065s - loss: 0.0365 - acc: 0.9814\n",
      "Epoch 25/30\n",
      " - 1060s - loss: 0.0363 - acc: 0.9817\n",
      "Epoch 26/30\n",
      " - 1061s - loss: 0.0360 - acc: 0.9819\n",
      "Epoch 27/30\n",
      " - 1062s - loss: 0.0357 - acc: 0.9822\n",
      "Epoch 28/30\n",
      " - 1062s - loss: 0.0355 - acc: 0.9826\n",
      "Epoch 29/30\n",
      " - 1061s - loss: 0.0353 - acc: 0.9828\n",
      "Epoch 30/30\n",
      " - 1060s - loss: 0.0351 - acc: 0.9830\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fa038944ac8>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, Y_train, epochs=30, batch_size=16, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.fit_generator(generator=batch_generator(X_train, Y_train, batch_size=32), \n",
    "#                    nb_epoch=10, samples_per_epoch=X_train.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2501/2501 [==============================] - 74s 29ms/step\n",
      "\n",
      "Loss = 0.04198011319066991\n",
      "Test Accuracy = 0.9778556274395378\n"
     ]
    }
   ],
   "source": [
    "preds = model.evaluate(x = X_test, y = Y_test)\n",
    "print()\n",
    "print (\"Loss = \" + str(preds[0]))\n",
    "print (\"Test Accuracy = \" + str(preds[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
