{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"<img src=\"https://raw.githubusercontent.com/EdsonAvelar/auc/master/molecular_banner.png\" width=1900px height=400px />","metadata":{}},{"cell_type":"markdown","source":"# Predicting Molecular Properties\n\n<h3 style=\"color:red\">If this Kernel Helps You! Please UP VOTE! üòÅ</h3>\n\n<h3> Can you measure the magnetic interactions between a pair of atoms? </h3>\n\nThis kernel is a combination of multiple kernels. The goal is to organize and explain the code to beginner competitors like me.<br>\nThis Kernels creates lots of new features and uses lightgbm as model","metadata":{}},{"cell_type":"markdown","source":"# Table of Contents:\n\n**1. [Problem Definition](#id1)** <br>\n**2. [Get the Data (Collect / Obtain)](#id2)** <br>\n**3. [Load the Dataset](#id3)** <br>\n**4. [Data Pre-processing](#id4)** <br>\n**5. [Model](#id5)** <br>\n**6. [Visualization and Analysis of Results](#id6)** <br>\n**7. [Submittion](#id7)** <br>\n**8. [References](#ref)** <br>","metadata":{}},{"cell_type":"markdown","source":"<a id=\"id1\"></a> <br> \n# **1. Problem Definition:** \n\nThis challenge aims to predict interactions between atoms. The main task is develop an algorithm that can predict the magnetic interaction between two atoms in a molecule (i.e., the scalar coupling constant)<br>\n\nIn this competition, you will be predicting the scalar_coupling_constant between atom pairs in molecules, given the two atom types (e.g., C and H), the coupling type (e.g., 2JHC), and any features you are able to create from the molecule structure (xyz) files.\n\n**Data**\n* **train.csv** - the training set, where the first column (molecule_name) is the name of the molecule where the coupling constant originates, the second (atom_index_0) and third column (atom_index_1) is the atom indices of the atom-pair creating the coupling and the fourth column (**scalar_coupling_constant**) is the scalar coupling constant that we want to be able to predict\n* **test.csv** - the test set; same info as train, without the target variable\n* **sample_submission.csv** - a sample submission file in the correct format\n* **structures.csv** - this file contains the same information as the individual xyz structure files, but in a single file\n\n**Additional Data**<br>\n*NOTE: additional data is provided for the molecules in Train only!*\n* **scalar_coupling_contributions.csv** - The scalar coupling constants in train.csv are a sum of four terms. The first column (**molecule_name**) are the name of the molecule, the second (**atom_index_0**) and third column (**atom_index_1**) are the atom indices of the atom-pair, the fourth column indicates the **type** of coupling, the fifth column (**fc**) is the Fermi Contact contribution, the sixth column (**sd**) is the Spin-dipolar contribution, the seventh column (**pso**) is the Paramagnetic spin-orbit contribution and the eighth column (**dso**) is the Diamagnetic spin-orbit contribution.\n\n","metadata":{}},{"cell_type":"markdown","source":"<a id=\"id2\"></a> <br> \n# **2. Get the Data (Collect / Obtain):** ","metadata":{}},{"cell_type":"markdown","source":"## All imports used in this kernel","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport os\n\nimport matplotlib.pyplot as plt\n%matplotlib inline\nfrom tqdm import tqdm_notebook\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.svm import NuSVR, SVR\nfrom sklearn.metrics import mean_absolute_error\npd.options.display.precision = 15\n\nimport lightgbm as lgb\nimport xgboost as xgb\nimport time\nimport datetime\nfrom catboost import CatBoostRegressor\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.model_selection import StratifiedKFold, KFold, RepeatedKFold\nfrom sklearn import metrics\nfrom sklearn import linear_model\nimport gc\nimport seaborn as sns\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\nfrom IPython.display import HTML\nimport json\nimport altair as alt\n\nimport networkx as nx\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport os\nimport time\nimport datetime\nimport json\nimport gc\nfrom numba import jit\n\nimport numpy as np\nimport pandas as pd\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom tqdm import tqdm_notebook\n\nimport lightgbm as lgb\nimport xgboost as xgb\nfrom catboost import CatBoostRegressor, CatBoostClassifier\nfrom sklearn import metrics\n\nfrom itertools import product\n\nimport altair as alt\nfrom altair.vega import v3\nfrom IPython.display import HTML\nalt.renderers.enable('notebook')","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_kg_hide-input":true,"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.status.busy":"2023-04-25T20:51:42.550590Z","iopub.execute_input":"2023-04-25T20:51:42.550966Z","iopub.status.idle":"2023-04-25T20:51:45.076666Z","shell.execute_reply.started":"2023-04-25T20:51:42.550897Z","shell.execute_reply":"2023-04-25T20:51:45.075634Z"},"trusted":true},"execution_count":1,"outputs":[{"execution_count":1,"output_type":"execute_result","data":{"text/plain":"RendererRegistry.enable('notebook')"},"metadata":{}}]},{"cell_type":"markdown","source":"## All function used in this kernel","metadata":{}},{"cell_type":"code","source":"# using ideas from this kernel: https://www.kaggle.com/notslush/altair-visualization-2018-stackoverflow-survey\ndef prepare_altair():\n    \"\"\"\n    Helper function to prepare altair for working.\n    \"\"\"\n    vega_url = 'https://cdn.jsdelivr.net/npm/vega@' + v3.SCHEMA_VERSION\n    vega_lib_url = 'https://cdn.jsdelivr.net/npm/vega-lib'\n    vega_lite_url = 'https://cdn.jsdelivr.net/npm/vega-lite@' + alt.SCHEMA_VERSION\n    vega_embed_url = 'https://cdn.jsdelivr.net/npm/vega-embed@3'\n    noext = \"?noext\"\n    \n    paths = {\n        'vega': vega_url + noext,\n        'vega-lib': vega_lib_url + noext,\n        'vega-lite': vega_lite_url + noext,\n        'vega-embed': vega_embed_url + noext\n    }\n    \n    workaround = f\"\"\"    requirejs.config({{\n        baseUrl: 'https://cdn.jsdelivr.net/npm/',\n        paths: {paths}\n    }});\n    \"\"\"\n    \n    return workaround\n    \n\ndef add_autoincrement(render_func):\n    # Keep track of unique <div/> IDs\n    cache = {}\n    def wrapped(chart, id=\"vega-chart\", autoincrement=True):\n        if autoincrement:\n            if id in cache:\n                counter = 1 + cache[id]\n                cache[id] = counter\n            else:\n                cache[id] = 0\n            actual_id = id if cache[id] == 0 else id + '-' + str(cache[id])\n        else:\n            if id not in cache:\n                cache[id] = 0\n            actual_id = id\n        return render_func(chart, id=actual_id)\n    # Cache will stay outside and \n    return wrapped\n           \n\n@add_autoincrement\ndef render(chart, id=\"vega-chart\"):\n    \"\"\"\n    Helper function to plot altair visualizations.\n    \"\"\"\n    chart_str = \"\"\"\n    <div id=\"{id}\"></div><script>\n    require([\"vega-embed\"], function(vg_embed) {{\n        const spec = {chart};     \n        vg_embed(\"#{id}\", spec, {{defaultStyle: true}}).catch(console.warn);\n        console.log(\"anything?\");\n    }});\n    console.log(\"really...anything?\");\n    </script>\n    \"\"\"\n    return HTML(\n        chart_str.format(\n            id=id,\n            chart=json.dumps(chart) if isinstance(chart, dict) else chart.to_json(indent=None)\n        )\n    )\n    \n\ndef reduce_mem_usage(df, verbose=True):\n    numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n    start_mem = df.memory_usage().sum() / 1024**2    \n    for col in df.columns:\n        col_type = df[col].dtypes\n        if col_type in numerics:\n            c_min = df[col].min()\n            c_max = df[col].max()\n            if str(col_type)[:3] == 'int':\n                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n                    df[col] = df[col].astype(np.int8)\n                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n                    df[col] = df[col].astype(np.int16)\n                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n                    df[col] = df[col].astype(np.int32)\n                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n                    df[col] = df[col].astype(np.int64)  \n            else:\n                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n                    df[col] = df[col].astype(np.float16)\n                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n                    df[col] = df[col].astype(np.float32)\n                else:\n                    df[col] = df[col].astype(np.float64)    \n    end_mem = df.memory_usage().sum() / 1024**2\n    if verbose: print('Mem. usage decreased to {:5.2f} Mb ({:.1f}% reduction)'.format(end_mem, 100 * (start_mem - end_mem) / start_mem))\n    return df\n    \n\n@jit\ndef fast_auc(y_true, y_prob):\n    \"\"\"\n    fast roc_auc computation: https://www.kaggle.com/c/microsoft-malware-prediction/discussion/76013\n    \"\"\"\n    y_true = np.asarray(y_true)\n    y_true = y_true[np.argsort(y_prob)]\n    nfalse = 0\n    auc = 0\n    n = len(y_true)\n    for i in range(n):\n        y_i = y_true[i]\n        nfalse += (1 - y_i)\n        auc += y_i * nfalse\n    auc /= (nfalse * (n - nfalse))\n    return auc\n\n\ndef eval_auc(y_true, y_pred):\n    \"\"\"\n    Fast auc eval function for lgb.\n    \"\"\"\n    return 'auc', fast_auc(y_true, y_pred), True\n\n\ndef group_mean_log_mae(y_true, y_pred, types, floor=1e-9):\n    \"\"\"\n    Fast metric computation for this competition: https://www.kaggle.com/c/champs-scalar-coupling\n    Code is from this kernel: https://www.kaggle.com/uberkinder/efficient-metric\n    \"\"\"\n    maes = (y_true-y_pred).abs().groupby(types).mean()\n    return np.log(maes.map(lambda x: max(x, floor))).mean()\n    \n\ndef train_model_regression(X, X_test, y, params, folds, model_type='lgb', eval_metric='mae', columns=None, plot_feature_importance=False, model=None,\n                               verbose=10000, early_stopping_rounds=200, n_estimators=50000):\n    \"\"\"\n    A function to train a variety of regression models.\n    Returns dictionary with oof predictions, test predictions, scores and, if necessary, feature importances.\n    \n    :params: X - training data, can be pd.DataFrame or np.ndarray (after normalizing)\n    :params: X_test - test data, can be pd.DataFrame or np.ndarray (after normalizing)\n    :params: y - target\n    :params: folds - folds to split data\n    :params: model_type - type of model to use\n    :params: eval_metric - metric to use\n    :params: columns - columns to use. If None - use all columns\n    :params: plot_feature_importance - whether to plot feature importance of LGB\n    :params: model - sklearn model, works only for \"sklearn\" model type\n    \n    \"\"\"\n    columns = X.columns if columns is None else columns\n    X_test = X_test[columns]\n    \n    # to set up scoring parameters\n    metrics_dict = {'mae': {'lgb_metric_name': 'mae',\n                        'catboost_metric_name': 'MAE',\n                        'sklearn_scoring_function': metrics.mean_absolute_error},\n                    'group_mae': {'lgb_metric_name': 'mae',\n                        'catboost_metric_name': 'MAE',\n                        'scoring_function': group_mean_log_mae},\n                    'mse': {'lgb_metric_name': 'mse',\n                        'catboost_metric_name': 'MSE',\n                        'sklearn_scoring_function': metrics.mean_squared_error}\n                    }\n\n    \n    result_dict = {}\n    \n    # out-of-fold predictions on train data\n    oof = np.zeros(len(X))\n    \n    # averaged predictions on train data\n    prediction = np.zeros(len(X_test))\n    \n    # list of scores on folds\n    scores = []\n    feature_importance = pd.DataFrame()\n    \n    # split and train on folds\n    for fold_n, (train_index, valid_index) in enumerate(folds.split(X)):\n        print(f'Fold {fold_n + 1} started at {time.ctime()}')\n        if type(X) == np.ndarray:\n            X_train, X_valid = X[columns][train_index], X[columns][valid_index]\n            y_train, y_valid = y[train_index], y[valid_index]\n        else:\n            X_train, X_valid = X[columns].iloc[train_index], X[columns].iloc[valid_index]\n            y_train, y_valid = y.iloc[train_index], y.iloc[valid_index]\n            \n        if model_type == 'lgb':\n            model = lgb.LGBMRegressor(**params, n_estimators = n_estimators, n_jobs = -1)\n            model.fit(X_train, y_train, \n                    eval_set=[(X_train, y_train), (X_valid, y_valid)], eval_metric=metrics_dict[eval_metric]['lgb_metric_name'],\n                    verbose=verbose, early_stopping_rounds=early_stopping_rounds)\n            \n            y_pred_valid = model.predict(X_valid)\n            y_pred = model.predict(X_test, num_iteration=model.best_iteration_)\n            \n        if model_type == 'xgb':\n            train_data = xgb.DMatrix(data=X_train, label=y_train, feature_names=X.columns)\n            valid_data = xgb.DMatrix(data=X_valid, label=y_valid, feature_names=X.columns)\n\n            watchlist = [(train_data, 'train'), (valid_data, 'valid_data')]\n            model = xgb.train(dtrain=train_data, num_boost_round=20000, evals=watchlist, early_stopping_rounds=200, verbose_eval=verbose, params=params)\n            y_pred_valid = model.predict(xgb.DMatrix(X_valid, feature_names=X.columns), ntree_limit=model.best_ntree_limit)\n            y_pred = model.predict(xgb.DMatrix(X_test, feature_names=X.columns), ntree_limit=model.best_ntree_limit)\n        \n        if model_type == 'sklearn':\n            model = model\n            model.fit(X_train, y_train)\n            \n            y_pred_valid = model.predict(X_valid).reshape(-1,)\n            score = metrics_dict[eval_metric]['sklearn_scoring_function'](y_valid, y_pred_valid)\n            print(f'Fold {fold_n}. {eval_metric}: {score:.4f}.')\n            print('')\n            \n            y_pred = model.predict(X_test).reshape(-1,)\n        \n        if model_type == 'cat':\n            model = CatBoostRegressor(iterations=20000,  eval_metric=metrics_dict[eval_metric]['catboost_metric_name'], **params,\n                                      loss_function=metrics_dict[eval_metric]['catboost_metric_name'])\n            model.fit(X_train, y_train, eval_set=(X_valid, y_valid), cat_features=[], use_best_model=True, verbose=False)\n\n            y_pred_valid = model.predict(X_valid)\n            y_pred = model.predict(X_test)\n        \n        oof[valid_index] = y_pred_valid.reshape(-1,)\n        if eval_metric != 'group_mae':\n            scores.append(metrics_dict[eval_metric]['sklearn_scoring_function'](y_valid, y_pred_valid))\n        else:\n            scores.append(metrics_dict[eval_metric]['scoring_function'](y_valid, y_pred_valid, X_valid['type']))\n\n        prediction += y_pred    \n        \n        if model_type == 'lgb' and plot_feature_importance:\n            # feature importance\n            fold_importance = pd.DataFrame()\n            fold_importance[\"feature\"] = columns\n            fold_importance[\"importance\"] = model.feature_importances_\n            fold_importance[\"fold\"] = fold_n + 1\n            feature_importance = pd.concat([feature_importance, fold_importance], axis=0)\n\n    prediction /= folds.n_splits\n    \n    print('CV mean score: {0:.4f}, std: {1:.4f}.'.format(np.mean(scores), np.std(scores)))\n    \n    result_dict['oof'] = oof\n    result_dict['prediction'] = prediction\n    result_dict['scores'] = scores\n    \n    if model_type == 'lgb':\n        if plot_feature_importance:\n            feature_importance[\"importance\"] /= folds.n_splits\n            cols = feature_importance[[\"feature\", \"importance\"]].groupby(\"feature\").mean().sort_values(\n                by=\"importance\", ascending=False)[:50].index\n\n            best_features = feature_importance.loc[feature_importance.feature.isin(cols)]\n\n            plt.figure(figsize=(16, 12));\n            sns.barplot(x=\"importance\", y=\"feature\", data=best_features.sort_values(by=\"importance\", ascending=False));\n            plt.title('LGB Features (avg over folds)');\n            \n            result_dict['feature_importance'] = feature_importance\n        \n    return result_dict\n    \n\n\ndef train_model_classification(X, X_test, y, params, folds, model_type='lgb', eval_metric='auc', columns=None, plot_feature_importance=False, model=None,\n                               verbose=10000, early_stopping_rounds=200, n_estimators=50000):\n    \"\"\"\n    A function to train a variety of regression models.\n    Returns dictionary with oof predictions, test predictions, scores and, if necessary, feature importances.\n    \n    :params: X - training data, can be pd.DataFrame or np.ndarray (after normalizing)\n    :params: X_test - test data, can be pd.DataFrame or np.ndarray (after normalizing)\n    :params: y - target\n    :params: folds - folds to split data\n    :params: model_type - type of model to use\n    :params: eval_metric - metric to use\n    :params: columns - columns to use. If None - use all columns\n    :params: plot_feature_importance - whether to plot feature importance of LGB\n    :params: model - sklearn model, works only for \"sklearn\" model type\n    \n    \"\"\"\n    columns = X.columns if columns == None else columns\n    X_test = X_test[columns]\n    \n    # to set up scoring parameters\n    metrics_dict = {'auc': {'lgb_metric_name': eval_auc,\n                        'catboost_metric_name': 'AUC',\n                        'sklearn_scoring_function': metrics.roc_auc_score},\n                    }\n    \n    result_dict = {}\n    \n    # out-of-fold predictions on train data\n    oof = np.zeros((len(X), len(set(y.values))))\n    \n    # averaged predictions on train data\n    prediction = np.zeros((len(X_test), oof.shape[1]))\n    \n    # list of scores on folds\n    scores = []\n    feature_importance = pd.DataFrame()\n    \n    # split and train on folds\n    for fold_n, (train_index, valid_index) in enumerate(folds.split(X)):\n        print(f'Fold {fold_n + 1} started at {time.ctime()}')\n        if type(X) == np.ndarray:\n            X_train, X_valid = X[columns][train_index], X[columns][valid_index]\n            y_train, y_valid = y[train_index], y[valid_index]\n        else:\n            X_train, X_valid = X[columns].iloc[train_index], X[columns].iloc[valid_index]\n            y_train, y_valid = y.iloc[train_index], y.iloc[valid_index]\n            \n        if model_type == 'lgb':\n            model = lgb.LGBMClassifier(**params, n_estimators=n_estimators, n_jobs = -1)\n            model.fit(X_train, y_train, \n                    eval_set=[(X_train, y_train), (X_valid, y_valid)], eval_metric=metrics_dict[eval_metric]['lgb_metric_name'],\n                    verbose=verbose, early_stopping_rounds=early_stopping_rounds)\n            \n            y_pred_valid = model.predict_proba(X_valid)\n            y_pred = model.predict_proba(X_test, num_iteration=model.best_iteration_)\n            \n        if model_type == 'xgb':\n            train_data = xgb.DMatrix(data=X_train, label=y_train, feature_names=X.columns)\n            valid_data = xgb.DMatrix(data=X_valid, label=y_valid, feature_names=X.columns)\n\n            watchlist = [(train_data, 'train'), (valid_data, 'valid_data')]\n            model = xgb.train(dtrain=train_data, num_boost_round=n_estimators, evals=watchlist, early_stopping_rounds=early_stopping_rounds, verbose_eval=verbose, params=params)\n            y_pred_valid = model.predict(xgb.DMatrix(X_valid, feature_names=X.columns), ntree_limit=model.best_ntree_limit)\n            y_pred = model.predict(xgb.DMatrix(X_test, feature_names=X.columns), ntree_limit=model.best_ntree_limit)\n        \n        if model_type == 'sklearn':\n            model = model\n            model.fit(X_train, y_train)\n            \n            y_pred_valid = model.predict(X_valid).reshape(-1,)\n            score = metrics_dict[eval_metric]['sklearn_scoring_function'](y_valid, y_pred_valid)\n            print(f'Fold {fold_n}. {eval_metric}: {score:.4f}.')\n            print('')\n            \n            y_pred = model.predict_proba(X_test)\n        \n        if model_type == 'cat':\n            model = CatBoostClassifier(iterations=n_estimators, eval_metric=metrics_dict[eval_metric]['catboost_metric_name'], **params,\n                                      loss_function=metrics_dict[eval_metric]['catboost_metric_name'])\n            model.fit(X_train, y_train, eval_set=(X_valid, y_valid), cat_features=[], use_best_model=True, verbose=False)\n\n            y_pred_valid = model.predict(X_valid)\n            y_pred = model.predict(X_test)\n        \n        oof[valid_index] = y_pred_valid\n        scores.append(metrics_dict[eval_metric]['sklearn_scoring_function'](y_valid, y_pred_valid[:, 1]))\n\n        prediction += y_pred    \n        \n        if model_type == 'lgb' and plot_feature_importance:\n            # feature importance\n            fold_importance = pd.DataFrame()\n            fold_importance[\"feature\"] = columns\n            fold_importance[\"importance\"] = model.feature_importances_\n            fold_importance[\"fold\"] = fold_n + 1\n            feature_importance = pd.concat([feature_importance, fold_importance], axis=0)\n\n    prediction /= folds.n_splits\n    \n    print('CV mean score: {0:.4f}, std: {1:.4f}.'.format(np.mean(scores), np.std(scores)))\n    \n    result_dict['oof'] = oof\n    result_dict['prediction'] = prediction\n    result_dict['scores'] = scores\n    \n    if model_type == 'lgb':\n        if plot_feature_importance:\n            feature_importance[\"importance\"] /= folds.n_splits\n            cols = feature_importance[[\"feature\", \"importance\"]].groupby(\"feature\").mean().sort_values(\n                by=\"importance\", ascending=False)[:50].index\n\n            best_features = feature_importance.loc[feature_importance.feature.isin(cols)]\n\n            plt.figure(figsize=(16, 12));\n            sns.barplot(x=\"importance\", y=\"feature\", data=best_features.sort_values(by=\"importance\", ascending=False));\n            plt.title('LGB Features (avg over folds)');\n            \n            result_dict['feature_importance'] = feature_importance\n        \n    return result_dict\n\n# setting up altair\nworkaround = prepare_altair()\nHTML(\"\".join((\n    \"<script>\",\n    workaround,\n    \"</script>\",\n)))","metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_kg_hide-input":true,"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","execution":{"iopub.status.busy":"2023-04-25T20:51:45.078574Z","iopub.execute_input":"2023-04-25T20:51:45.078946Z","iopub.status.idle":"2023-04-25T20:51:45.328119Z","shell.execute_reply.started":"2023-04-25T20:51:45.078873Z","shell.execute_reply":"2023-04-25T20:51:45.327141Z"},"trusted":true},"execution_count":2,"outputs":[{"execution_count":2,"output_type":"execute_result","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<script>    requirejs.config({\n        baseUrl: 'https://cdn.jsdelivr.net/npm/',\n        paths: {'vega': 'https://cdn.jsdelivr.net/npm/vega@v3.3.1?noext', 'vega-lib': 'https://cdn.jsdelivr.net/npm/vega-lib?noext', 'vega-lite': 'https://cdn.jsdelivr.net/npm/vega-lite@v2.6.0?noext', 'vega-embed': 'https://cdn.jsdelivr.net/npm/vega-embed@3?noext'}\n    });\n    </script>"},"metadata":{}}]},{"cell_type":"markdown","source":"<a id=\"id3\"></a> <br> \n# **3. Load the Dataset** \n\nLet's load all necessary datasets","metadata":{}},{"cell_type":"code","source":"train = pd.read_csv('../input/train.csv')\ntest = pd.read_csv('../input/test.csv')\nsub = pd.read_csv('../input/sample_submission.csv')\nstructures = pd.read_csv('../input/structures.csv')\nscalar_coupling_contributions = pd.read_csv('../input/scalar_coupling_contributions.csv')\n\nprint('Train dataset shape is -> rows: {} cols:{}'.format(train.shape[0],train.shape[1]))\nprint('Test dataset shape is  -> rows: {} cols:{}'.format(test.shape[0],test.shape[1]))\nprint('Sub dataset shape is  -> rows: {} cols:{}'.format(sub.shape[0],sub.shape[1]))\nprint('Structures dataset shape is  -> rows: {} cols:{}'.format(structures.shape[0],structures.shape[1]))\nprint('Scalar_coupling_contributions dataset shape is  -> rows: {} cols:{}'.format(scalar_coupling_contributions.shape[0],\n                                                                                   scalar_coupling_contributions.shape[1]))","metadata":{"execution":{"iopub.status.busy":"2023-04-25T20:51:45.329417Z","iopub.execute_input":"2023-04-25T20:51:45.329751Z","iopub.status.idle":"2023-04-25T20:53:20.545291Z","shell.execute_reply.started":"2023-04-25T20:51:45.329662Z","shell.execute_reply":"2023-04-25T20:53:20.544382Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"Train dataset shape is -> rows: 4659076 cols:6\nTest dataset shape is  -> rows: 2505190 cols:5\nSub dataset shape is  -> rows: 2505190 cols:2\nStructures dataset shape is  -> rows: 2358875 cols:6\nScalar_coupling_contributions dataset shape is  -> rows: 4659076 cols:8\n","output_type":"stream"}]},{"cell_type":"markdown","source":"For an fast model/feature evaluation, get only 10% of dataset. Final submission must remove/coments this code","metadata":{}},{"cell_type":"code","source":"n_estimators_default = 4000","metadata":{"execution":{"iopub.status.busy":"2023-04-25T20:53:20.546452Z","iopub.execute_input":"2023-04-25T20:53:20.546720Z","iopub.status.idle":"2023-04-25T20:53:20.550505Z","shell.execute_reply.started":"2023-04-25T20:53:20.546672Z","shell.execute_reply":"2023-04-25T20:53:20.549672Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"'''\nsize = round(0.10*train.shape[0])\ntrain = train[:size]\ntest = test[:size]\nsub = sub[:size]\nstructures = structures[:size]\nscalar_coupling_contributions = scalar_coupling_contributions[:size]\n\nprint('Train dataset shape is now rows: {} cols:{}'.format(train.shape[0],train.shape[1]))\nprint('Test dataset shape is now rows: {} cols:{}'.format(test.shape[0],test.shape[1]))\nprint('Sub dataset shape is now rows: {} cols:{}'.format(sub.shape[0],sub.shape[1]))\nprint('Structures dataset shape is now rows: {} cols:{}'.format(structures.shape[0],structures.shape[1]))\nprint('Scalar_coupling_contributions dataset shape is now rows: {} cols:{}'.format(scalar_coupling_contributions.shape[0],\n                                                                                   scalar_coupling_contributions.shape[1]))\n'''","metadata":{"execution":{"iopub.status.busy":"2023-04-25T20:53:20.551401Z","iopub.execute_input":"2023-04-25T20:53:20.551651Z","iopub.status.idle":"2023-04-25T20:53:20.565827Z","shell.execute_reply.started":"2023-04-25T20:53:20.551569Z","shell.execute_reply":"2023-04-25T20:53:20.565040Z"},"trusted":true},"execution_count":5,"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"\"\\nsize = round(0.10*train.shape[0])\\ntrain = train[:size]\\ntest = test[:size]\\nsub = sub[:size]\\nstructures = structures[:size]\\nscalar_coupling_contributions = scalar_coupling_contributions[:size]\\n\\nprint('Train dataset shape is now rows: {} cols:{}'.format(train.shape[0],train.shape[1]))\\nprint('Test dataset shape is now rows: {} cols:{}'.format(test.shape[0],test.shape[1]))\\nprint('Sub dataset shape is now rows: {} cols:{}'.format(sub.shape[0],sub.shape[1]))\\nprint('Structures dataset shape is now rows: {} cols:{}'.format(structures.shape[0],structures.shape[1]))\\nprint('Scalar_coupling_contributions dataset shape is now rows: {} cols:{}'.format(scalar_coupling_contributions.shape[0],\\n                                                                                   scalar_coupling_contributions.shape[1]))\\n\""},"metadata":{}}]},{"cell_type":"markdown","source":"The importante things to know is that the scalar coupling constants in train.csv are a sum of four terms. \n```\n* fc is the Fermi Contact contribution\n* sd is the Spin-dipolar contribution\n* pso is the Paramagnetic spin-orbit contribution\n* dso is the Diamagnetic spin-orbit contribution. \n```\nLet's merge this into train","metadata":{}},{"cell_type":"code","source":"train = pd.merge(train, scalar_coupling_contributions, how = 'left',\n                  left_on  = ['molecule_name', 'atom_index_0', 'atom_index_1', 'type'],\n                  right_on = ['molecule_name', 'atom_index_0', 'atom_index_1', 'type'])","metadata":{"execution":{"iopub.status.busy":"2023-04-25T20:53:20.566778Z","iopub.execute_input":"2023-04-25T20:53:20.567012Z","iopub.status.idle":"2023-04-25T20:53:25.385470Z","shell.execute_reply.started":"2023-04-25T20:53:20.566971Z","shell.execute_reply":"2023-04-25T20:53:25.384665Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"train.head(10)","metadata":{"execution":{"iopub.status.busy":"2023-04-25T20:53:25.386996Z","iopub.execute_input":"2023-04-25T20:53:25.387265Z","iopub.status.idle":"2023-04-25T20:53:25.428345Z","shell.execute_reply.started":"2023-04-25T20:53:25.387212Z","shell.execute_reply":"2023-04-25T20:53:25.427401Z"},"trusted":true},"execution_count":7,"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"   id     molecule_name  atom_index_0    ...           sd      pso       dso\n0   0  dsgdb9nsd_000001             1    ...     0.254579  1.25862  0.272010\n1   1  dsgdb9nsd_000001             1    ...     0.352978  2.85839 -3.433600\n2   2  dsgdb9nsd_000001             1    ...     0.352944  2.85852 -3.433870\n3   3  dsgdb9nsd_000001             1    ...     0.352934  2.85855 -3.433930\n4   4  dsgdb9nsd_000001             2    ...     0.254585  1.25861  0.272013\n5   5  dsgdb9nsd_000001             2    ...     0.352932  2.85856 -3.433950\n6   6  dsgdb9nsd_000001             2    ...     0.352943  2.85853 -3.433870\n7   7  dsgdb9nsd_000001             3    ...     0.254634  1.25856  0.272012\n8   8  dsgdb9nsd_000001             3    ...     0.352943  2.85856 -3.433930\n9   9  dsgdb9nsd_000001             4    ...     0.254628  1.25856  0.272012\n\n[10 rows x 10 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>molecule_name</th>\n      <th>atom_index_0</th>\n      <th>atom_index_1</th>\n      <th>type</th>\n      <th>scalar_coupling_constant</th>\n      <th>fc</th>\n      <th>sd</th>\n      <th>pso</th>\n      <th>dso</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>dsgdb9nsd_000001</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1JHC</td>\n      <td>84.807599999999994</td>\n      <td>83.022400000000005</td>\n      <td>0.254579</td>\n      <td>1.25862</td>\n      <td>0.272010</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>dsgdb9nsd_000001</td>\n      <td>1</td>\n      <td>2</td>\n      <td>2JHH</td>\n      <td>-11.257000000000000</td>\n      <td>-11.034700000000001</td>\n      <td>0.352978</td>\n      <td>2.85839</td>\n      <td>-3.433600</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>dsgdb9nsd_000001</td>\n      <td>1</td>\n      <td>3</td>\n      <td>2JHH</td>\n      <td>-11.254799999999999</td>\n      <td>-11.032500000000001</td>\n      <td>0.352944</td>\n      <td>2.85852</td>\n      <td>-3.433870</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>dsgdb9nsd_000001</td>\n      <td>1</td>\n      <td>4</td>\n      <td>2JHH</td>\n      <td>-11.254300000000001</td>\n      <td>-11.031900000000000</td>\n      <td>0.352934</td>\n      <td>2.85855</td>\n      <td>-3.433930</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>dsgdb9nsd_000001</td>\n      <td>2</td>\n      <td>0</td>\n      <td>1JHC</td>\n      <td>84.807400000000001</td>\n      <td>83.022199999999998</td>\n      <td>0.254585</td>\n      <td>1.25861</td>\n      <td>0.272013</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>5</td>\n      <td>dsgdb9nsd_000001</td>\n      <td>2</td>\n      <td>3</td>\n      <td>2JHH</td>\n      <td>-11.254099999999999</td>\n      <td>-11.031700000000001</td>\n      <td>0.352932</td>\n      <td>2.85856</td>\n      <td>-3.433950</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>6</td>\n      <td>dsgdb9nsd_000001</td>\n      <td>2</td>\n      <td>4</td>\n      <td>2JHH</td>\n      <td>-11.254799999999999</td>\n      <td>-11.032400000000001</td>\n      <td>0.352943</td>\n      <td>2.85853</td>\n      <td>-3.433870</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>7</td>\n      <td>dsgdb9nsd_000001</td>\n      <td>3</td>\n      <td>0</td>\n      <td>1JHC</td>\n      <td>84.809299999999993</td>\n      <td>83.024100000000004</td>\n      <td>0.254634</td>\n      <td>1.25856</td>\n      <td>0.272012</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>8</td>\n      <td>dsgdb9nsd_000001</td>\n      <td>3</td>\n      <td>4</td>\n      <td>2JHH</td>\n      <td>-11.254300000000001</td>\n      <td>-11.031900000000000</td>\n      <td>0.352943</td>\n      <td>2.85856</td>\n      <td>-3.433930</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>9</td>\n      <td>dsgdb9nsd_000001</td>\n      <td>4</td>\n      <td>0</td>\n      <td>1JHC</td>\n      <td>84.809500000000000</td>\n      <td>83.024299999999997</td>\n      <td>0.254628</td>\n      <td>1.25856</td>\n      <td>0.272012</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"test.head(10)","metadata":{"execution":{"iopub.status.busy":"2023-04-25T20:53:25.429664Z","iopub.execute_input":"2023-04-25T20:53:25.429961Z","iopub.status.idle":"2023-04-25T20:53:25.448646Z","shell.execute_reply.started":"2023-04-25T20:53:25.429904Z","shell.execute_reply":"2023-04-25T20:53:25.447729Z"},"trusted":true},"execution_count":8,"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"        id     molecule_name  atom_index_0  atom_index_1  type\n0  4659076  dsgdb9nsd_000004             2             0  2JHC\n1  4659077  dsgdb9nsd_000004             2             1  1JHC\n2  4659078  dsgdb9nsd_000004             2             3  3JHH\n3  4659079  dsgdb9nsd_000004             3             0  1JHC\n4  4659080  dsgdb9nsd_000004             3             1  2JHC\n5  4659081  dsgdb9nsd_000014             3             0  1JHC\n6  4659082  dsgdb9nsd_000014             3             1  2JHC\n7  4659083  dsgdb9nsd_000014             3             4  2JHH\n8  4659084  dsgdb9nsd_000014             3             5  2JHH\n9  4659085  dsgdb9nsd_000014             3             6  3JHH","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>molecule_name</th>\n      <th>atom_index_0</th>\n      <th>atom_index_1</th>\n      <th>type</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>4659076</td>\n      <td>dsgdb9nsd_000004</td>\n      <td>2</td>\n      <td>0</td>\n      <td>2JHC</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>4659077</td>\n      <td>dsgdb9nsd_000004</td>\n      <td>2</td>\n      <td>1</td>\n      <td>1JHC</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>4659078</td>\n      <td>dsgdb9nsd_000004</td>\n      <td>2</td>\n      <td>3</td>\n      <td>3JHH</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4659079</td>\n      <td>dsgdb9nsd_000004</td>\n      <td>3</td>\n      <td>0</td>\n      <td>1JHC</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4659080</td>\n      <td>dsgdb9nsd_000004</td>\n      <td>3</td>\n      <td>1</td>\n      <td>2JHC</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>4659081</td>\n      <td>dsgdb9nsd_000014</td>\n      <td>3</td>\n      <td>0</td>\n      <td>1JHC</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>4659082</td>\n      <td>dsgdb9nsd_000014</td>\n      <td>3</td>\n      <td>1</td>\n      <td>2JHC</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>4659083</td>\n      <td>dsgdb9nsd_000014</td>\n      <td>3</td>\n      <td>4</td>\n      <td>2JHH</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>4659084</td>\n      <td>dsgdb9nsd_000014</td>\n      <td>3</td>\n      <td>5</td>\n      <td>2JHH</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>4659085</td>\n      <td>dsgdb9nsd_000014</td>\n      <td>3</td>\n      <td>6</td>\n      <td>3JHH</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"scalar_coupling_contributions.head(5)","metadata":{"execution":{"iopub.status.busy":"2023-04-25T20:53:25.450120Z","iopub.execute_input":"2023-04-25T20:53:25.450463Z","iopub.status.idle":"2023-04-25T20:53:25.479246Z","shell.execute_reply.started":"2023-04-25T20:53:25.450381Z","shell.execute_reply":"2023-04-25T20:53:25.478178Z"},"trusted":true},"execution_count":9,"outputs":[{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"      molecule_name  atom_index_0    ...         pso       dso\n0  dsgdb9nsd_000001             1    ...     1.25862  0.272010\n1  dsgdb9nsd_000001             1    ...     2.85839 -3.433600\n2  dsgdb9nsd_000001             1    ...     2.85852 -3.433870\n3  dsgdb9nsd_000001             1    ...     2.85855 -3.433930\n4  dsgdb9nsd_000001             2    ...     1.25861  0.272013\n\n[5 rows x 8 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>molecule_name</th>\n      <th>atom_index_0</th>\n      <th>atom_index_1</th>\n      <th>type</th>\n      <th>fc</th>\n      <th>sd</th>\n      <th>pso</th>\n      <th>dso</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>dsgdb9nsd_000001</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1JHC</td>\n      <td>83.022400000000005</td>\n      <td>0.254579</td>\n      <td>1.25862</td>\n      <td>0.272010</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>dsgdb9nsd_000001</td>\n      <td>1</td>\n      <td>2</td>\n      <td>2JHH</td>\n      <td>-11.034700000000001</td>\n      <td>0.352978</td>\n      <td>2.85839</td>\n      <td>-3.433600</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>dsgdb9nsd_000001</td>\n      <td>1</td>\n      <td>3</td>\n      <td>2JHH</td>\n      <td>-11.032500000000001</td>\n      <td>0.352944</td>\n      <td>2.85852</td>\n      <td>-3.433870</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>dsgdb9nsd_000001</td>\n      <td>1</td>\n      <td>4</td>\n      <td>2JHH</td>\n      <td>-11.031900000000000</td>\n      <td>0.352934</td>\n      <td>2.85855</td>\n      <td>-3.433930</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>dsgdb9nsd_000001</td>\n      <td>2</td>\n      <td>0</td>\n      <td>1JHC</td>\n      <td>83.022199999999998</td>\n      <td>0.254585</td>\n      <td>1.25861</td>\n      <td>0.272013</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"`train['scalar_coupling_constant'] and scalar_coupling_contributions['fc']` quite similar","metadata":{}},{"cell_type":"code","source":"pd.concat(objs=[train['scalar_coupling_constant'],scalar_coupling_contributions['fc'] ],axis=1)[:10]","metadata":{"execution":{"iopub.status.busy":"2023-04-25T20:53:25.480563Z","iopub.execute_input":"2023-04-25T20:53:25.480982Z","iopub.status.idle":"2023-04-25T20:53:25.611735Z","shell.execute_reply.started":"2023-04-25T20:53:25.480904Z","shell.execute_reply":"2023-04-25T20:53:25.610818Z"},"trusted":true},"execution_count":10,"outputs":[{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"   scalar_coupling_constant                  fc\n0        84.807599999999994  83.022400000000005\n1       -11.257000000000000 -11.034700000000001\n2       -11.254799999999999 -11.032500000000001\n3       -11.254300000000001 -11.031900000000000\n4        84.807400000000001  83.022199999999998\n5       -11.254099999999999 -11.031700000000001\n6       -11.254799999999999 -11.032400000000001\n7        84.809299999999993  83.024100000000004\n8       -11.254300000000001 -11.031900000000000\n9        84.809500000000000  83.024299999999997","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>scalar_coupling_constant</th>\n      <th>fc</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>84.807599999999994</td>\n      <td>83.022400000000005</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>-11.257000000000000</td>\n      <td>-11.034700000000001</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>-11.254799999999999</td>\n      <td>-11.032500000000001</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>-11.254300000000001</td>\n      <td>-11.031900000000000</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>84.807400000000001</td>\n      <td>83.022199999999998</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>-11.254099999999999</td>\n      <td>-11.031700000000001</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>-11.254799999999999</td>\n      <td>-11.032400000000001</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>84.809299999999993</td>\n      <td>83.024100000000004</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>-11.254300000000001</td>\n      <td>-11.031900000000000</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>84.809500000000000</td>\n      <td>83.024299999999997</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"Based in others ideais we can:<br>\n\n- train a model to predict `fc` feature;\n- add this feature to train and test and train the same model to compare performance;\n- train a better model;","metadata":{}},{"cell_type":"markdown","source":"<a id=\"id4\"></a> <br> \n# **4. Data Pre-processing** ","metadata":{}},{"cell_type":"markdown","source":"## Feature generation","metadata":{}},{"cell_type":"markdown","source":"I use this great kernel to get x,y,z position. https://www.kaggle.com/seriousran/just-speed-up-calculate-distance-from-benchmark","metadata":{}},{"cell_type":"code","source":"from tqdm import tqdm_notebook as tqdm\natomic_radius = {'H':0.38, 'C':0.77, 'N':0.75, 'O':0.73, 'F':0.71} # Without fudge factor\n\nfudge_factor = 0.05\natomic_radius = {k:v + fudge_factor for k,v in atomic_radius.items()}\nprint(atomic_radius)\n\nelectronegativity = {'H':2.2, 'C':2.55, 'N':3.04, 'O':3.44, 'F':3.98}\n\n#structures = pd.read_csv(structures, dtype={'atom_index':np.int8})\n\natoms = structures['atom'].values\natoms_en = [electronegativity[x] for x in tqdm(atoms)]\natoms_rad = [atomic_radius[x] for x in tqdm(atoms)]\n\nstructures['EN'] = atoms_en\nstructures['rad'] = atoms_rad\n\ndisplay(structures.head())","metadata":{"execution":{"iopub.status.busy":"2023-04-25T20:53:25.613608Z","iopub.execute_input":"2023-04-25T20:53:25.614010Z","iopub.status.idle":"2023-04-25T20:53:28.314159Z","shell.execute_reply.started":"2023-04-25T20:53:25.613942Z","shell.execute_reply":"2023-04-25T20:53:28.313512Z"},"trusted":true},"execution_count":11,"outputs":[{"name":"stdout","text":"{'H': 0.43, 'C': 0.8200000000000001, 'N': 0.8, 'O': 0.78, 'F': 0.76}\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"HBox(children=(IntProgress(value=0, max=2358875), HTML(value='')))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b1962e9bc4fd406d9b5566aa917f728b"}},"metadata":{}},{"name":"stdout","text":"\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"HBox(children=(IntProgress(value=0, max=2358875), HTML(value='')))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3b3166a264724915a626f98af9611c7f"}},"metadata":{}},{"name":"stdout","text":"\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"      molecule_name  atom_index atom  ...              z    EN   rad\n0  dsgdb9nsd_000001           0    C  ...   0.0080009958  2.55  0.82\n1  dsgdb9nsd_000001           1    H  ...   0.0019761204  2.20  0.43\n2  dsgdb9nsd_000001           2    H  ...   0.0002765748  2.20  0.43\n3  dsgdb9nsd_000001           3    H  ...  -0.8766437152  2.20  0.43\n4  dsgdb9nsd_000001           4    H  ...   0.9063972942  2.20  0.43\n\n[5 rows x 8 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>molecule_name</th>\n      <th>atom_index</th>\n      <th>atom</th>\n      <th>x</th>\n      <th>y</th>\n      <th>z</th>\n      <th>EN</th>\n      <th>rad</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>dsgdb9nsd_000001</td>\n      <td>0</td>\n      <td>C</td>\n      <td>-0.0126981359</td>\n      <td>1.0858041578</td>\n      <td>0.0080009958</td>\n      <td>2.55</td>\n      <td>0.82</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>dsgdb9nsd_000001</td>\n      <td>1</td>\n      <td>H</td>\n      <td>0.0021504160</td>\n      <td>-0.0060313176</td>\n      <td>0.0019761204</td>\n      <td>2.20</td>\n      <td>0.43</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>dsgdb9nsd_000001</td>\n      <td>2</td>\n      <td>H</td>\n      <td>1.0117308433</td>\n      <td>1.4637511618</td>\n      <td>0.0002765748</td>\n      <td>2.20</td>\n      <td>0.43</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>dsgdb9nsd_000001</td>\n      <td>3</td>\n      <td>H</td>\n      <td>-0.5408150690</td>\n      <td>1.4475266138</td>\n      <td>-0.8766437152</td>\n      <td>2.20</td>\n      <td>0.43</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>dsgdb9nsd_000001</td>\n      <td>4</td>\n      <td>H</td>\n      <td>-0.5238136345</td>\n      <td>1.4379326443</td>\n      <td>0.9063972942</td>\n      <td>2.20</td>\n      <td>0.43</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"### Chemical Bond Calculation","metadata":{}},{"cell_type":"code","source":"i_atom = structures['atom_index'].values\np = structures[['x', 'y', 'z']].values\np_compare = p\nm = structures['molecule_name'].values\nm_compare = m\nr = structures['rad'].values\nr_compare = r\n\nsource_row = np.arange(len(structures))\nmax_atoms = 28\n\nbonds = np.zeros((len(structures)+1, max_atoms+1), dtype=np.int8)\nbond_dists = np.zeros((len(structures)+1, max_atoms+1), dtype=np.float32)\n\nprint('Calculating bonds')\n\nfor i in tqdm(range(max_atoms-1)):\n    p_compare = np.roll(p_compare, -1, axis=0)\n    m_compare = np.roll(m_compare, -1, axis=0)\n    r_compare = np.roll(r_compare, -1, axis=0)\n    \n    mask = np.where(m == m_compare, 1, 0) #Are we still comparing atoms in the same molecule?\n    dists = np.linalg.norm(p - p_compare, axis=1) * mask\n    r_bond = r + r_compare\n    \n    bond = np.where(np.logical_and(dists > 0.0001, dists < r_bond), 1, 0)\n    \n    source_row = source_row\n    target_row = source_row + i + 1 #Note: Will be out of bounds of bonds array for some values of i\n    target_row = np.where(np.logical_or(target_row > len(structures), mask==0), len(structures), target_row) #If invalid target, write to dummy row\n    \n    source_atom = i_atom\n    target_atom = i_atom + i + 1 #Note: Will be out of bounds of bonds array for some values of i\n    target_atom = np.where(np.logical_or(target_atom > max_atoms, mask==0), max_atoms, target_atom) #If invalid target, write to dummy col\n    \n    bonds[(source_row, target_atom)] = bond\n    bonds[(target_row, source_atom)] = bond\n    bond_dists[(source_row, target_atom)] = dists\n    bond_dists[(target_row, source_atom)] = dists\n\nbonds = np.delete(bonds, axis=0, obj=-1) #Delete dummy row\nbonds = np.delete(bonds, axis=1, obj=-1) #Delete dummy col\nbond_dists = np.delete(bond_dists, axis=0, obj=-1) #Delete dummy row\nbond_dists = np.delete(bond_dists, axis=1, obj=-1) #Delete dummy col\n\nprint('Counting and condensing bonds')\n\nbonds_numeric = [[i for i,x in enumerate(row) if x] for row in tqdm(bonds)]\nbond_lengths = [[dist for i,dist in enumerate(row) if i in bonds_numeric[j]] for j,row in enumerate(tqdm(bond_dists))]\nbond_lengths_mean = [ np.mean(x) for x in bond_lengths]\nbond_lengths_std = [ np.std(x) for x in bond_lengths]\nn_bonds = [len(x) for x in bonds_numeric]\n\n#bond_data = {'bond_' + str(i):col for i, col in enumerate(np.transpose(bonds))}\n#bond_data.update({'bonds_numeric':bonds_numeric, 'n_bonds':n_bonds})\n\nbond_data = {'n_bonds':n_bonds, 'bond_lengths_mean': bond_lengths_mean,'bond_lengths_std':bond_lengths_std }\nbond_df = pd.DataFrame(bond_data)\nstructures = structures.join(bond_df)\ndisplay(structures.head(20))","metadata":{"execution":{"iopub.status.busy":"2023-04-25T20:53:28.315710Z","iopub.execute_input":"2023-04-25T20:53:28.316066Z","iopub.status.idle":"2023-04-25T20:56:03.779565Z","shell.execute_reply.started":"2023-04-25T20:53:28.315999Z","shell.execute_reply":"2023-04-25T20:56:03.778728Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stdout","text":"Calculating bonds\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"HBox(children=(IntProgress(value=0, max=27), HTML(value='')))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7a487ba95aa54f74a33d4f138d9aa7b7"}},"metadata":{}},{"name":"stdout","text":"\nCounting and condensing bonds\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"HBox(children=(IntProgress(value=0, max=2358875), HTML(value='')))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b587068c2ae64bebaf17c12a347d4bd4"}},"metadata":{}},{"name":"stdout","text":"\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"HBox(children=(IntProgress(value=0, max=2358875), HTML(value='')))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"aba3cbc0d3a4423aab1bdc456fa1914e"}},"metadata":{}},{"name":"stdout","text":"\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"       molecule_name        ...           bond_lengths_std\n0   dsgdb9nsd_000001        ...          0.000002762467830\n1   dsgdb9nsd_000001        ...          0.000000000000000\n2   dsgdb9nsd_000001        ...          0.000000000000000\n3   dsgdb9nsd_000001        ...          0.000000000000000\n4   dsgdb9nsd_000001        ...          0.000000000000000\n5   dsgdb9nsd_000002        ...          0.000009144474461\n6   dsgdb9nsd_000002        ...          0.000000000000000\n7   dsgdb9nsd_000002        ...          0.000000000000000\n8   dsgdb9nsd_000002        ...          0.000000000000000\n9   dsgdb9nsd_000003        ...          0.000000000000000\n10  dsgdb9nsd_000003        ...          0.000000000000000\n11  dsgdb9nsd_000003        ...          0.000000000000000\n12  dsgdb9nsd_000004        ...          0.068489968776703\n13  dsgdb9nsd_000004        ...          0.068489968776703\n14  dsgdb9nsd_000004        ...          0.000000000000000\n15  dsgdb9nsd_000004        ...          0.000000000000000\n16  dsgdb9nsd_000005        ...          0.042574942111969\n17  dsgdb9nsd_000005        ...          0.000000000000000\n18  dsgdb9nsd_000005        ...          0.000000000000000\n19  dsgdb9nsd_000006        ...          0.041982222348452\n\n[20 rows x 11 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>molecule_name</th>\n      <th>atom_index</th>\n      <th>atom</th>\n      <th>x</th>\n      <th>y</th>\n      <th>z</th>\n      <th>EN</th>\n      <th>rad</th>\n      <th>n_bonds</th>\n      <th>bond_lengths_mean</th>\n      <th>bond_lengths_std</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>dsgdb9nsd_000001</td>\n      <td>0</td>\n      <td>C</td>\n      <td>-0.0126981359</td>\n      <td>1.0858041578</td>\n      <td>0.0080009958</td>\n      <td>2.55</td>\n      <td>0.82</td>\n      <td>4</td>\n      <td>1.091949701309204</td>\n      <td>0.000002762467830</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>dsgdb9nsd_000001</td>\n      <td>1</td>\n      <td>H</td>\n      <td>0.0021504160</td>\n      <td>-0.0060313176</td>\n      <td>0.0019761204</td>\n      <td>2.20</td>\n      <td>0.43</td>\n      <td>1</td>\n      <td>1.091953039169312</td>\n      <td>0.000000000000000</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>dsgdb9nsd_000001</td>\n      <td>2</td>\n      <td>H</td>\n      <td>1.0117308433</td>\n      <td>1.4637511618</td>\n      <td>0.0002765748</td>\n      <td>2.20</td>\n      <td>0.43</td>\n      <td>1</td>\n      <td>1.091951608657837</td>\n      <td>0.000000000000000</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>dsgdb9nsd_000001</td>\n      <td>3</td>\n      <td>H</td>\n      <td>-0.5408150690</td>\n      <td>1.4475266138</td>\n      <td>-0.8766437152</td>\n      <td>2.20</td>\n      <td>0.43</td>\n      <td>1</td>\n      <td>1.091946363449097</td>\n      <td>0.000000000000000</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>dsgdb9nsd_000001</td>\n      <td>4</td>\n      <td>H</td>\n      <td>-0.5238136345</td>\n      <td>1.4379326443</td>\n      <td>0.9063972942</td>\n      <td>2.20</td>\n      <td>0.43</td>\n      <td>1</td>\n      <td>1.091947555541992</td>\n      <td>0.000000000000000</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>dsgdb9nsd_000002</td>\n      <td>0</td>\n      <td>N</td>\n      <td>-0.0404260543</td>\n      <td>1.0241077531</td>\n      <td>0.0625637998</td>\n      <td>3.04</td>\n      <td>0.80</td>\n      <td>3</td>\n      <td>1.017194986343384</td>\n      <td>0.000009144474461</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>dsgdb9nsd_000002</td>\n      <td>1</td>\n      <td>H</td>\n      <td>0.0172574639</td>\n      <td>0.0125452063</td>\n      <td>-0.0273771593</td>\n      <td>2.20</td>\n      <td>0.43</td>\n      <td>1</td>\n      <td>1.017189979553223</td>\n      <td>0.000000000000000</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>dsgdb9nsd_000002</td>\n      <td>2</td>\n      <td>H</td>\n      <td>0.9157893661</td>\n      <td>1.3587451948</td>\n      <td>-0.0287577581</td>\n      <td>2.20</td>\n      <td>0.43</td>\n      <td>1</td>\n      <td>1.017187237739563</td>\n      <td>0.000000000000000</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>dsgdb9nsd_000002</td>\n      <td>3</td>\n      <td>H</td>\n      <td>-0.5202777357</td>\n      <td>1.3435321258</td>\n      <td>-0.7755426124</td>\n      <td>2.20</td>\n      <td>0.43</td>\n      <td>1</td>\n      <td>1.017207860946655</td>\n      <td>0.000000000000000</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>dsgdb9nsd_000003</td>\n      <td>0</td>\n      <td>O</td>\n      <td>-0.0343604951</td>\n      <td>0.9775395708</td>\n      <td>0.0076015923</td>\n      <td>3.44</td>\n      <td>0.78</td>\n      <td>2</td>\n      <td>0.962106823921204</td>\n      <td>0.000000000000000</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>dsgdb9nsd_000003</td>\n      <td>1</td>\n      <td>H</td>\n      <td>0.0647664923</td>\n      <td>0.0205721989</td>\n      <td>0.0015346341</td>\n      <td>2.20</td>\n      <td>0.43</td>\n      <td>1</td>\n      <td>0.962106823921204</td>\n      <td>0.000000000000000</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>dsgdb9nsd_000003</td>\n      <td>2</td>\n      <td>H</td>\n      <td>0.8717903737</td>\n      <td>1.3007924048</td>\n      <td>0.0006931336</td>\n      <td>2.20</td>\n      <td>0.43</td>\n      <td>1</td>\n      <td>0.962106823921204</td>\n      <td>0.000000000000000</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>dsgdb9nsd_000004</td>\n      <td>0</td>\n      <td>C</td>\n      <td>0.5995394918</td>\n      <td>0.0000000000</td>\n      <td>1.0000000000</td>\n      <td>2.55</td>\n      <td>0.82</td>\n      <td>2</td>\n      <td>1.130589008331299</td>\n      <td>0.068489968776703</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>dsgdb9nsd_000004</td>\n      <td>1</td>\n      <td>C</td>\n      <td>-0.5995394918</td>\n      <td>0.0000000000</td>\n      <td>1.0000000000</td>\n      <td>2.55</td>\n      <td>0.82</td>\n      <td>2</td>\n      <td>1.130589008331299</td>\n      <td>0.068489968776703</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>dsgdb9nsd_000004</td>\n      <td>2</td>\n      <td>H</td>\n      <td>-1.6616385861</td>\n      <td>0.0000000000</td>\n      <td>1.0000000000</td>\n      <td>2.20</td>\n      <td>0.43</td>\n      <td>1</td>\n      <td>1.062099099159241</td>\n      <td>0.000000000000000</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>dsgdb9nsd_000004</td>\n      <td>3</td>\n      <td>H</td>\n      <td>1.6616385861</td>\n      <td>0.0000000000</td>\n      <td>1.0000000000</td>\n      <td>2.20</td>\n      <td>0.43</td>\n      <td>1</td>\n      <td>1.062099099159241</td>\n      <td>0.000000000000000</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>dsgdb9nsd_000005</td>\n      <td>0</td>\n      <td>C</td>\n      <td>-0.0133239314</td>\n      <td>1.1324657151</td>\n      <td>0.0082758861</td>\n      <td>2.55</td>\n      <td>0.82</td>\n      <td>2</td>\n      <td>1.109173059463501</td>\n      <td>0.042574942111969</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>dsgdb9nsd_000005</td>\n      <td>1</td>\n      <td>N</td>\n      <td>0.0023107217</td>\n      <td>-0.0191585871</td>\n      <td>0.0019287305</td>\n      <td>3.04</td>\n      <td>0.80</td>\n      <td>1</td>\n      <td>1.151747941970825</td>\n      <td>0.000000000000000</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>dsgdb9nsd_000005</td>\n      <td>2</td>\n      <td>H</td>\n      <td>-0.0278026991</td>\n      <td>2.1989492963</td>\n      <td>0.0141537903</td>\n      <td>2.20</td>\n      <td>0.43</td>\n      <td>1</td>\n      <td>1.066598057746887</td>\n      <td>0.000000000000000</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>dsgdb9nsd_000006</td>\n      <td>0</td>\n      <td>C</td>\n      <td>-0.0139776956</td>\n      <td>1.1802114286</td>\n      <td>0.0077524981</td>\n      <td>2.55</td>\n      <td>0.82</td>\n      <td>3</td>\n      <td>1.140626907348633</td>\n      <td>0.041982222348452</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"def map_atom_info(df, atom_idx):\n    df = pd.merge(df, structures, how = 'left',\n                  left_on  = ['molecule_name', f'atom_index_{atom_idx}'],\n                  right_on = ['molecule_name',  'atom_index'])\n    \n    #df = df.drop('atom_index', axis=1)\n    df = df.rename(columns={'atom': f'atom_{atom_idx}',\n                            'x': f'x_{atom_idx}',\n                            'y': f'y_{atom_idx}',\n                            'z': f'z_{atom_idx}'})\n    return df\n\ntrain = map_atom_info(train, 0)\ntrain = map_atom_info(train, 1)\n\ntest = map_atom_info(test, 0)\ntest = map_atom_info(test, 1)","metadata":{"execution":{"iopub.status.busy":"2023-04-25T20:56:03.780895Z","iopub.execute_input":"2023-04-25T20:56:03.781347Z","iopub.status.idle":"2023-04-25T20:56:32.590763Z","shell.execute_reply.started":"2023-04-25T20:56:03.781267Z","shell.execute_reply":"2023-04-25T20:56:32.589763Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"markdown","source":"Let's get the distance between atoms first.","metadata":{}},{"cell_type":"code","source":"train_p_0 = train[['x_0', 'y_0', 'z_0']].values\ntrain_p_1 = train[['x_1', 'y_1', 'z_1']].values\ntest_p_0 = test[['x_0', 'y_0', 'z_0']].values\ntest_p_1 = test[['x_1', 'y_1', 'z_1']].values\n\ntrain['dist'] = np.linalg.norm(train_p_0 - train_p_1, axis=1)\ntest['dist'] = np.linalg.norm(test_p_0 - test_p_1, axis=1)\ntrain['dist_x'] = (train['x_0'] - train['x_1']) ** 2\ntest['dist_x'] = (test['x_0'] - test['x_1']) ** 2\ntrain['dist_y'] = (train['y_0'] - train['y_1']) ** 2\ntest['dist_y'] = (test['y_0'] - test['y_1']) ** 2\ntrain['dist_z'] = (train['z_0'] - train['z_1']) ** 2\ntest['dist_z'] = (test['z_0'] - test['z_1']) ** 2\n\ntrain['type_0'] = train['type'].apply(lambda x: x[0])\ntest['type_0'] = test['type'].apply(lambda x: x[0])\n","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2023-04-25T20:56:32.592206Z","iopub.execute_input":"2023-04-25T20:56:32.592532Z","iopub.status.idle":"2023-04-25T20:56:35.562749Z","shell.execute_reply.started":"2023-04-25T20:56:32.592478Z","shell.execute_reply":"2023-04-25T20:56:35.561746Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"def create_features(df):\n    df['molecule_couples'] = df.groupby('molecule_name')['id'].transform('count')\n    df['molecule_dist_mean'] = df.groupby('molecule_name')['dist'].transform('mean')\n    df['molecule_dist_min'] = df.groupby('molecule_name')['dist'].transform('min')\n    df['molecule_dist_max'] = df.groupby('molecule_name')['dist'].transform('max')\n    df['atom_0_couples_count'] = df.groupby(['molecule_name', 'atom_index_0'])['id'].transform('count')\n    df['atom_1_couples_count'] = df.groupby(['molecule_name', 'atom_index_1'])['id'].transform('count')\n    df[f'molecule_atom_index_0_x_1_std'] = df.groupby(['molecule_name', 'atom_index_0'])['x_1'].transform('std')\n    df[f'molecule_atom_index_0_y_1_mean'] = df.groupby(['molecule_name', 'atom_index_0'])['y_1'].transform('mean')\n    df[f'molecule_atom_index_0_y_1_mean_diff'] = df[f'molecule_atom_index_0_y_1_mean'] - df['y_1']\n    df[f'molecule_atom_index_0_y_1_mean_div'] = df[f'molecule_atom_index_0_y_1_mean'] / df['y_1']\n    df[f'molecule_atom_index_0_y_1_max'] = df.groupby(['molecule_name', 'atom_index_0'])['y_1'].transform('max')\n    df[f'molecule_atom_index_0_y_1_max_diff'] = df[f'molecule_atom_index_0_y_1_max'] - df['y_1']\n    df[f'molecule_atom_index_0_y_1_std'] = df.groupby(['molecule_name', 'atom_index_0'])['y_1'].transform('std')\n    df[f'molecule_atom_index_0_z_1_std'] = df.groupby(['molecule_name', 'atom_index_0'])['z_1'].transform('std')\n    df[f'molecule_atom_index_0_dist_mean'] = df.groupby(['molecule_name', 'atom_index_0'])['dist'].transform('mean')\n    df[f'molecule_atom_index_0_dist_mean_diff'] = df[f'molecule_atom_index_0_dist_mean'] - df['dist']\n    df[f'molecule_atom_index_0_dist_mean_div'] = df[f'molecule_atom_index_0_dist_mean'] / df['dist']\n    df[f'molecule_atom_index_0_dist_max'] = df.groupby(['molecule_name', 'atom_index_0'])['dist'].transform('max')\n    df[f'molecule_atom_index_0_dist_max_diff'] = df[f'molecule_atom_index_0_dist_max'] - df['dist']\n    df[f'molecule_atom_index_0_dist_max_div'] = df[f'molecule_atom_index_0_dist_max'] / df['dist']\n    df[f'molecule_atom_index_0_dist_min'] = df.groupby(['molecule_name', 'atom_index_0'])['dist'].transform('min')\n    df[f'molecule_atom_index_0_dist_min_diff'] = df[f'molecule_atom_index_0_dist_min'] - df['dist']\n    df[f'molecule_atom_index_0_dist_min_div'] = df[f'molecule_atom_index_0_dist_min'] / df['dist']\n    df[f'molecule_atom_index_0_dist_std'] = df.groupby(['molecule_name', 'atom_index_0'])['dist'].transform('std')\n    df[f'molecule_atom_index_0_dist_std_diff'] = df[f'molecule_atom_index_0_dist_std'] - df['dist']\n    df[f'molecule_atom_index_0_dist_std_div'] = df[f'molecule_atom_index_0_dist_std'] / df['dist']\n    df[f'molecule_atom_index_1_dist_mean'] = df.groupby(['molecule_name', 'atom_index_1'])['dist'].transform('mean')\n    df[f'molecule_atom_index_1_dist_mean_diff'] = df[f'molecule_atom_index_1_dist_mean'] - df['dist']\n    df[f'molecule_atom_index_1_dist_mean_div'] = df[f'molecule_atom_index_1_dist_mean'] / df['dist']\n    df[f'molecule_atom_index_1_dist_max'] = df.groupby(['molecule_name', 'atom_index_1'])['dist'].transform('max')\n    df[f'molecule_atom_index_1_dist_max_diff'] = df[f'molecule_atom_index_1_dist_max'] - df['dist']\n    df[f'molecule_atom_index_1_dist_max_div'] = df[f'molecule_atom_index_1_dist_max'] / df['dist']\n    df[f'molecule_atom_index_1_dist_min'] = df.groupby(['molecule_name', 'atom_index_1'])['dist'].transform('min')\n    df[f'molecule_atom_index_1_dist_min_diff'] = df[f'molecule_atom_index_1_dist_min'] - df['dist']\n    df[f'molecule_atom_index_1_dist_min_div'] = df[f'molecule_atom_index_1_dist_min'] / df['dist']\n    df[f'molecule_atom_index_1_dist_std'] = df.groupby(['molecule_name', 'atom_index_1'])['dist'].transform('std')\n    df[f'molecule_atom_index_1_dist_std_diff'] = df[f'molecule_atom_index_1_dist_std'] - df['dist']\n    df[f'molecule_atom_index_1_dist_std_div'] = df[f'molecule_atom_index_1_dist_std'] / df['dist']\n    df[f'molecule_atom_1_dist_mean'] = df.groupby(['molecule_name', 'atom_1'])['dist'].transform('mean')\n    df[f'molecule_atom_1_dist_min'] = df.groupby(['molecule_name', 'atom_1'])['dist'].transform('min')\n    df[f'molecule_atom_1_dist_min_diff'] = df[f'molecule_atom_1_dist_min'] - df['dist']\n    df[f'molecule_atom_1_dist_min_div'] = df[f'molecule_atom_1_dist_min'] / df['dist']\n    df[f'molecule_atom_1_dist_std'] = df.groupby(['molecule_name', 'atom_1'])['dist'].transform('std')\n    df[f'molecule_atom_1_dist_std_diff'] = df[f'molecule_atom_1_dist_std'] - df['dist']\n    df[f'molecule_type_0_dist_std'] = df.groupby(['molecule_name', 'type_0'])['dist'].transform('std')\n    df[f'molecule_type_0_dist_std_diff'] = df[f'molecule_type_0_dist_std'] - df['dist']\n    df[f'molecule_type_dist_mean'] = df.groupby(['molecule_name', 'type'])['dist'].transform('mean')\n    df[f'molecule_type_dist_mean_diff'] = df[f'molecule_type_dist_mean'] - df['dist']\n    df[f'molecule_type_dist_mean_div'] = df[f'molecule_type_dist_mean'] / df['dist']\n    df[f'molecule_type_dist_max'] = df.groupby(['molecule_name', 'type'])['dist'].transform('max')\n    df[f'molecule_type_dist_min'] = df.groupby(['molecule_name', 'type'])['dist'].transform('min')\n    df[f'molecule_type_dist_std'] = df.groupby(['molecule_name', 'type'])['dist'].transform('std')\n    df[f'molecule_type_dist_std_diff'] = df[f'molecule_type_dist_std'] - df['dist']\n    df = reduce_mem_usage(df)\n    return df\n\ntrain = create_features(train)\ntest = create_features(test)","metadata":{"execution":{"iopub.status.busy":"2023-04-25T20:56:35.565735Z","iopub.execute_input":"2023-04-25T20:56:35.566330Z","iopub.status.idle":"2023-04-25T21:01:59.429256Z","shell.execute_reply.started":"2023-04-25T20:56:35.566254Z","shell.execute_reply":"2023-04-25T21:01:59.428141Z"},"trusted":true},"execution_count":15,"outputs":[{"name":"stdout","text":"Mem. usage decreased to 933.08 Mb (70.5% reduction)\nMem. usage decreased to 487.38 Mb (69.6% reduction)\n","output_type":"stream"}]},{"cell_type":"code","source":"def map_atom_info(df_1,df_2, atom_idx):\n    df = pd.merge(df_1, df_2, how = 'left',\n                  left_on  = ['molecule_name', f'atom_index_{atom_idx}'],\n                  right_on = ['molecule_name',  'atom_index'])\n    df = df.drop('atom_index', axis=1)\n\n    return df\n\ndef create_closest(df_train):\n    #I apologize for my poor coding skill. Please make the better one.\n    df_temp=df_train.loc[:,[\"molecule_name\",\"atom_index_0\",\"atom_index_1\",\"dist\",\"x_0\",\"y_0\",\"z_0\",\"x_1\",\"y_1\",\"z_1\"]].copy()\n    df_temp_=df_temp.copy()\n    df_temp_= df_temp_.rename(columns={'atom_index_0': 'atom_index_1',\n                                       'atom_index_1': 'atom_index_0',\n                                       'x_0': 'x_1',\n                                       'y_0': 'y_1',\n                                       'z_0': 'z_1',\n                                       'x_1': 'x_0',\n                                       'y_1': 'y_0',\n                                       'z_1': 'z_0'})\n    df_temp=pd.concat(objs=[df_temp,df_temp_],axis=0)\n\n    df_temp[\"min_distance\"]=df_temp.groupby(['molecule_name', 'atom_index_0'])['dist'].transform('min')\n    df_temp= df_temp[df_temp[\"min_distance\"]==df_temp[\"dist\"]]\n\n    df_temp=df_temp.drop(['x_0','y_0','z_0','min_distance'], axis=1)\n    df_temp= df_temp.rename(columns={'atom_index_0': 'atom_index',\n                                     'atom_index_1': 'atom_index_closest',\n                                     'distance': 'distance_closest',\n                                     'x_1': 'x_closest',\n                                     'y_1': 'y_closest',\n                                     'z_1': 'z_closest'})\n\n    for atom_idx in [0,1]:\n        df_train = map_atom_info(df_train,df_temp, atom_idx)\n        df_train = df_train.rename(columns={'atom_index_closest': f'atom_index_closest_{atom_idx}',\n                                            'distance_closest': f'distance_closest_{atom_idx}',\n                                            'x_closest': f'x_closest_{atom_idx}',\n                                            'y_closest': f'y_closest_{atom_idx}',\n                                            'z_closest': f'z_closest_{atom_idx}'})\n    return df_train\n\n#dtrain = create_closest(train)\n#dtest = create_closest(test)\n#print('dtrain size',dtrain.shape)\n#print('dtest size',dtest.shape)","metadata":{"execution":{"iopub.status.busy":"2023-04-25T21:01:59.430620Z","iopub.execute_input":"2023-04-25T21:01:59.430915Z","iopub.status.idle":"2023-04-25T21:01:59.441862Z","shell.execute_reply.started":"2023-04-25T21:01:59.430855Z","shell.execute_reply":"2023-04-25T21:01:59.440919Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"markdown","source":"### cosine angles calculation","metadata":{}},{"cell_type":"code","source":"def add_cos_features(df):\n    df[\"distance_0\"]=((df['x_0']-df['x_closest_0'])**2+(df['y_0']-df['y_closest_0'])**2+(df['z_0']-df['z_closest_0'])**2)**(1/2)\n    df[\"distance_1\"]=((df['x_1']-df['x_closest_1'])**2+(df['y_1']-df['y_closest_1'])**2+(df['z_1']-df['z_closest_1'])**2)**(1/2)\n    df[\"vec_0_x\"]=(df['x_0']-df['x_closest_0'])/df[\"distance_0\"]\n    df[\"vec_0_y\"]=(df['y_0']-df['y_closest_0'])/df[\"distance_0\"]\n    df[\"vec_0_z\"]=(df['z_0']-df['z_closest_0'])/df[\"distance_0\"]\n    df[\"vec_1_x\"]=(df['x_1']-df['x_closest_1'])/df[\"distance_1\"]\n    df[\"vec_1_y\"]=(df['y_1']-df['y_closest_1'])/df[\"distance_1\"]\n    df[\"vec_1_z\"]=(df['z_1']-df['z_closest_1'])/df[\"distance_1\"]\n    df[\"vec_x\"]=(df['x_1']-df['x_0'])/df[\"dist\"]\n    df[\"vec_y\"]=(df['y_1']-df['y_0'])/df[\"dist\"]\n    df[\"vec_z\"]=(df['z_1']-df['z_0'])/df[\"dist\"]\n    df[\"cos_0_1\"]=df[\"vec_0_x\"]*df[\"vec_1_x\"]+df[\"vec_0_y\"]*df[\"vec_1_y\"]+df[\"vec_0_z\"]*df[\"vec_1_z\"]\n    df[\"cos_0\"]=df[\"vec_0_x\"]*df[\"vec_x\"]+df[\"vec_0_y\"]*df[\"vec_y\"]+df[\"vec_0_z\"]*df[\"vec_z\"]\n    df[\"cos_1\"]=df[\"vec_1_x\"]*df[\"vec_x\"]+df[\"vec_1_y\"]*df[\"vec_y\"]+df[\"vec_1_z\"]*df[\"vec_z\"]\n    df=df.drop(['vec_0_x','vec_0_y','vec_0_z','vec_1_x','vec_1_y','vec_1_z','vec_x','vec_y','vec_z'], axis=1)\n    return df\n    \n#train = add_cos_features(train)\n#test = add_cos_features(test)\n\n#print('train size',train.shape)\n#print('test size',test.shape)","metadata":{"execution":{"iopub.status.busy":"2023-04-25T21:01:59.443066Z","iopub.execute_input":"2023-04-25T21:01:59.443375Z","iopub.status.idle":"2023-04-25T21:01:59.458897Z","shell.execute_reply.started":"2023-04-25T21:01:59.443287Z","shell.execute_reply":"2023-04-25T21:01:59.457781Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"markdown","source":"Dropping molecule_name and encode atom_0, atom_1 and type_0.<br>\n**@TODO:** Try others encoders ","metadata":{}},{"cell_type":"code","source":"del_cols_list = ['id','molecule_name','sd','pso','dso']\ndef del_cols(df, cols):\n    del_cols_list_ = [l for l in del_cols_list if l in df]\n    df = df.drop(del_cols_list_,axis=1)\n    return df\n\ntrain = del_cols(train,del_cols_list)\ntest = del_cols(test,del_cols_list)","metadata":{"execution":{"iopub.status.busy":"2023-04-25T21:01:59.460388Z","iopub.execute_input":"2023-04-25T21:01:59.460750Z","iopub.status.idle":"2023-04-25T21:02:05.395279Z","shell.execute_reply.started":"2023-04-25T21:01:59.460685Z","shell.execute_reply":"2023-04-25T21:02:05.394434Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"def encode_categoric_single(df):\n    lbl = LabelEncoder()\n    cat_cols=[]\n    try:\n        cat_cols = df.describe(include=['O']).columns.tolist()\n        for cat in cat_cols:\n            df[cat] = lbl.fit_transform(list(df[cat].values))\n    except Exception as e:\n        print('error: ', str(e) )\n\n    return df","metadata":{"execution":{"iopub.status.busy":"2023-04-25T21:02:05.396595Z","iopub.execute_input":"2023-04-25T21:02:05.396891Z","iopub.status.idle":"2023-04-25T21:02:05.402486Z","shell.execute_reply.started":"2023-04-25T21:02:05.396848Z","shell.execute_reply":"2023-04-25T21:02:05.401432Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"def encode_categoric(dtrain,dtest):\n    lbl = LabelEncoder()\n    objs_n = len(dtrain)\n    dfmerge = pd.concat(objs=[dtrain,dtest],axis=0)\n    cat_cols=[]\n    try:\n        cat_cols = dfmerge.describe(include=['O']).columns.tolist()\n        for cat in cat_cols:\n            dfmerge[cat] = lbl.fit_transform(list(dfmerge[cat].values))\n    except Exception as e:\n        print('error: ', str(e) )\n\n    dtrain = dfmerge[:objs_n]\n    dtest = dfmerge[objs_n:]\n    return dtrain,dtest\n\n","metadata":{"execution":{"iopub.status.busy":"2023-04-25T21:02:05.403892Z","iopub.execute_input":"2023-04-25T21:02:05.404394Z","iopub.status.idle":"2023-04-25T21:02:05.413280Z","shell.execute_reply.started":"2023-04-25T21:02:05.404336Z","shell.execute_reply":"2023-04-25T21:02:05.412648Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"train = encode_categoric_single(train)\ntest = encode_categoric_single(test)","metadata":{"execution":{"iopub.status.busy":"2023-04-25T21:02:05.414382Z","iopub.execute_input":"2023-04-25T21:02:05.414912Z","iopub.status.idle":"2023-04-25T21:02:18.970260Z","shell.execute_reply.started":"2023-04-25T21:02:05.414854Z","shell.execute_reply":"2023-04-25T21:02:18.969176Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"y_fc = train['fc']\nX = train.drop(['scalar_coupling_constant','fc'],axis=1)\ny = train['scalar_coupling_constant']\n\nX_test = test.copy()","metadata":{"execution":{"iopub.status.busy":"2023-04-25T21:02:18.971622Z","iopub.execute_input":"2023-04-25T21:02:18.971916Z","iopub.status.idle":"2023-04-25T21:02:21.994563Z","shell.execute_reply.started":"2023-04-25T21:02:18.971855Z","shell.execute_reply":"2023-04-25T21:02:21.993865Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"print('X size',X.shape)\nprint('X_test size',X_test.shape)\nprint('dtest size',test.shape)\nprint('y_fc size',y_fc.shape)\n\ndel train, test\ngc.collect()\n","metadata":{"execution":{"iopub.status.busy":"2023-04-25T21:02:21.995495Z","iopub.execute_input":"2023-04-25T21:02:21.995894Z","iopub.status.idle":"2023-04-25T21:02:22.580368Z","shell.execute_reply.started":"2023-04-25T21:02:21.995830Z","shell.execute_reply":"2023-04-25T21:02:22.579468Z"},"trusted":true},"execution_count":23,"outputs":[{"name":"stdout","text":"X size (4659076, 81)\nX_test size (2505190, 81)\ndtest size (2505190, 81)\ny_fc size (4659076,)\n","output_type":"stream"},{"execution_count":23,"output_type":"execute_result","data":{"text/plain":"154"},"metadata":{}}]},{"cell_type":"code","source":"good_columns = ['type',\n 'bond_lengths_mean_y',\n 'bond_lengths_std_y',\n 'bond_lengths_mean_x',\n 'molecule_atom_index_0_dist_min_div',\n 'molecule_atom_index_0_dist_std_div',\n 'molecule_atom_index_0_dist_mean',\n 'molecule_atom_index_0_dist_max',\n 'dist_y',\n 'molecule_atom_index_1_dist_std_diff',\n 'z_0',\n 'molecule_type_dist_min',\n 'molecule_atom_index_0_y_1_mean_div',\n 'dist_x',\n 'x_0',\n 'y_0',\n 'molecule_type_dist_std',\n 'molecule_atom_index_0_y_1_std',\n 'molecule_dist_mean',\n 'molecule_atom_index_0_dist_std_diff',\n 'dist_z',\n 'molecule_atom_index_0_dist_std',\n 'molecule_atom_index_0_x_1_std',\n 'molecule_type_dist_std_diff',\n 'molecule_type_0_dist_std',\n 'dist',\n 'molecule_atom_index_0_dist_mean_diff',\n 'molecule_atom_index_1_dist_min_div',\n 'molecule_atom_index_1_dist_mean_diff',\n 'y_1',\n 'molecule_type_dist_mean_div',\n 'molecule_dist_max',\n 'molecule_atom_index_0_dist_mean_div',\n 'z_1',\n 'molecule_atom_index_0_z_1_std',\n 'molecule_atom_index_1_dist_mean_div',\n 'molecule_atom_index_1_dist_min_diff',\n 'molecule_atom_index_1_dist_mean',\n 'molecule_atom_index_1_dist_min',\n 'molecule_atom_index_1_dist_max',\n 'molecule_type_0_dist_std_diff',\n 'molecule_atom_index_0_dist_min_diff',\n 'molecule_type_dist_mean_diff',\n 'x_1',\n 'molecule_atom_index_0_y_1_max',\n 'molecule_atom_index_0_y_1_mean_diff',\n 'molecule_atom_1_dist_std_diff',\n 'molecule_atom_index_0_y_1_mean',\n 'molecule_atom_1_dist_std',\n 'molecule_type_dist_max']\n\nX = X[good_columns].copy()\nX_test = X_test[good_columns].copy()","metadata":{"execution":{"iopub.status.busy":"2023-04-25T21:02:22.581481Z","iopub.execute_input":"2023-04-25T21:02:22.581750Z","iopub.status.idle":"2023-04-25T21:02:25.888405Z","shell.execute_reply.started":"2023-04-25T21:02:22.581701Z","shell.execute_reply":"2023-04-25T21:02:25.887655Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"markdown","source":"<a id=\"id5\"></a> <br> \n# **5. Model** \n","metadata":{}},{"cell_type":"code","source":"n_fold = 5\nfolds = KFold(n_splits=n_fold, shuffle=True, random_state=11)","metadata":{"execution":{"iopub.status.busy":"2023-04-25T21:02:25.889548Z","iopub.execute_input":"2023-04-25T21:02:25.889830Z","iopub.status.idle":"2023-04-25T21:02:25.893740Z","shell.execute_reply.started":"2023-04-25T21:02:25.889783Z","shell.execute_reply":"2023-04-25T21:02:25.892981Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"markdown","source":"## Create out of fold feature","metadata":{}},{"cell_type":"code","source":"params = {'num_leaves': 50,\n          'min_child_samples': 79,\n          'min_data_in_leaf': 100,\n          'objective': 'regression',\n          'max_depth': 9,\n          'learning_rate': 0.2,\n          \"boosting_type\": \"gbdt\",\n          \"subsample_freq\": 1,\n          \"subsample\": 0.9,\n          \"bagging_seed\": 11,\n          \"metric\": 'mae',\n          \"verbosity\": -1,\n          'reg_alpha': 0.1,\n          'reg_lambda': 0.3,\n          'colsample_bytree': 1.0\n         }","metadata":{"execution":{"iopub.status.busy":"2023-04-25T21:02:25.895063Z","iopub.execute_input":"2023-04-25T21:02:25.895352Z","iopub.status.idle":"2023-04-25T21:02:25.906243Z","shell.execute_reply.started":"2023-04-25T21:02:25.895294Z","shell.execute_reply":"2023-04-25T21:02:25.905491Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"X_short = pd.DataFrame({'ind': list(X.index), 'type': X['type'].values, 'oof': [0] * len(X), 'target': y_fc.values})\nX_short_test = pd.DataFrame({'ind': list(X_test.index), 'type': X_test['type'].values, 'prediction': [0] * len(X_test)})\nresult_dict_lgb_oof =  {}\nfor t in X['type'].unique():\n    print(f'Training of type {t}')\n    X_t = X.loc[X['type'] == t]\n    X_test_t = X_test.loc[X_test['type'] == t]\n    y_t = X_short.loc[X_short['type'] == t, 'target']\n    result_dict_lgb_oof = train_model_regression(X=X_t, X_test=X_test_t, y=y_t, params=params, folds=folds, model_type='lgb', eval_metric='group_mae', plot_feature_importance=False,\n                                                      verbose=500, early_stopping_rounds=200, n_estimators=n_estimators_default)\n    X_short.loc[X_short['type'] == t, 'oof'] = result_dict_lgb_oof['oof']\n    X_short_test.loc[X_short_test['type'] == t, 'prediction'] = result_dict_lgb_oof['prediction']","metadata":{"execution":{"iopub.status.busy":"2023-04-25T21:02:25.907794Z","iopub.execute_input":"2023-04-25T21:02:25.908101Z","iopub.status.idle":"2023-04-25T23:52:51.087655Z","shell.execute_reply.started":"2023-04-25T21:02:25.908045Z","shell.execute_reply":"2023-04-25T23:52:51.086490Z"},"trusted":true},"execution_count":27,"outputs":[{"name":"stdout","text":"Training of type 0\nFold 1 started at Tue Apr 25 21:02:30 2023\nTraining until validation scores don't improve for 200 rounds.\n[500]\ttraining's l1: 1.65691\tvalid_1's l1: 1.80059\n[1000]\ttraining's l1: 1.42616\tvalid_1's l1: 1.66549\n[1500]\ttraining's l1: 1.27282\tvalid_1's l1: 1.59112\n[2000]\ttraining's l1: 1.1595\tvalid_1's l1: 1.54657\n[2500]\ttraining's l1: 1.0681\tvalid_1's l1: 1.51602\n[3000]\ttraining's l1: 0.991082\tvalid_1's l1: 1.49309\n[3500]\ttraining's l1: 0.923433\tvalid_1's l1: 1.47343\n[4000]\ttraining's l1: 0.864522\tvalid_1's l1: 1.45965\nDid not meet early stopping. Best iteration is:\n[4000]\ttraining's l1: 0.864522\tvalid_1's l1: 1.45965\nFold 2 started at Tue Apr 25 21:07:28 2023\nTraining until validation scores don't improve for 200 rounds.\n[500]\ttraining's l1: 1.65839\tvalid_1's l1: 1.80229\n[1000]\ttraining's l1: 1.42127\tvalid_1's l1: 1.6625\n[1500]\ttraining's l1: 1.26964\tvalid_1's l1: 1.59126\n[2000]\ttraining's l1: 1.15788\tvalid_1's l1: 1.5453\n[2500]\ttraining's l1: 1.06678\tvalid_1's l1: 1.5147\n[3000]\ttraining's l1: 0.989918\tvalid_1's l1: 1.49146\n[3500]\ttraining's l1: 0.92294\tvalid_1's l1: 1.47384\n[4000]\ttraining's l1: 0.864035\tvalid_1's l1: 1.46009\nDid not meet early stopping. Best iteration is:\n[4000]\ttraining's l1: 0.864035\tvalid_1's l1: 1.46009\nFold 3 started at Tue Apr 25 21:12:38 2023\nTraining until validation scores don't improve for 200 rounds.\n[500]\ttraining's l1: 1.64966\tvalid_1's l1: 1.79275\n[1000]\ttraining's l1: 1.42068\tvalid_1's l1: 1.66201\n[1500]\ttraining's l1: 1.26945\tvalid_1's l1: 1.58921\n[2000]\ttraining's l1: 1.15705\tvalid_1's l1: 1.54467\n[2500]\ttraining's l1: 1.065\tvalid_1's l1: 1.51277\n[3000]\ttraining's l1: 0.989062\tvalid_1's l1: 1.4914\n[3500]\ttraining's l1: 0.922211\tvalid_1's l1: 1.47352\n[4000]\ttraining's l1: 0.862064\tvalid_1's l1: 1.45871\nDid not meet early stopping. Best iteration is:\n[4000]\ttraining's l1: 0.862064\tvalid_1's l1: 1.45871\nFold 4 started at Tue Apr 25 21:17:33 2023\nTraining until validation scores don't improve for 200 rounds.\n[500]\ttraining's l1: 1.65736\tvalid_1's l1: 1.79982\n[1000]\ttraining's l1: 1.42208\tvalid_1's l1: 1.66169\n[1500]\ttraining's l1: 1.2708\tvalid_1's l1: 1.58956\n[2000]\ttraining's l1: 1.15793\tvalid_1's l1: 1.54528\n[2500]\ttraining's l1: 1.06607\tvalid_1's l1: 1.5141\n[3000]\ttraining's l1: 0.989511\tvalid_1's l1: 1.49076\n[3500]\ttraining's l1: 0.923716\tvalid_1's l1: 1.47378\n[4000]\ttraining's l1: 0.865086\tvalid_1's l1: 1.46013\nDid not meet early stopping. Best iteration is:\n[4000]\ttraining's l1: 0.865086\tvalid_1's l1: 1.46013\nFold 5 started at Tue Apr 25 21:22:27 2023\nTraining until validation scores don't improve for 200 rounds.\n[500]\ttraining's l1: 1.65175\tvalid_1's l1: 1.79985\n[1000]\ttraining's l1: 1.42083\tvalid_1's l1: 1.66262\n[1500]\ttraining's l1: 1.27157\tvalid_1's l1: 1.59204\n[2000]\ttraining's l1: 1.1592\tvalid_1's l1: 1.54734\n[2500]\ttraining's l1: 1.06716\tvalid_1's l1: 1.51437\n[3000]\ttraining's l1: 0.990292\tvalid_1's l1: 1.491\n[3500]\ttraining's l1: 0.924388\tvalid_1's l1: 1.47365\n[4000]\ttraining's l1: 0.865431\tvalid_1's l1: 1.45871\nDid not meet early stopping. Best iteration is:\n[4000]\ttraining's l1: 0.865431\tvalid_1's l1: 1.45871\nCV mean score: 0.3781, std: 0.0004.\nTraining of type 3\nFold 1 started at Tue Apr 25 21:27:34 2023\nTraining until validation scores don't improve for 200 rounds.\n[500]\ttraining's l1: 0.368429\tvalid_1's l1: 0.432335\n[1000]\ttraining's l1: 0.299603\tvalid_1's l1: 0.401319\n[1500]\ttraining's l1: 0.256353\tvalid_1's l1: 0.38593\n[2000]\ttraining's l1: 0.22479\tvalid_1's l1: 0.376656\n[2500]\ttraining's l1: 0.19982\tvalid_1's l1: 0.370179\n[3000]\ttraining's l1: 0.179361\tvalid_1's l1: 0.366152\n[3500]\ttraining's l1: 0.162274\tvalid_1's l1: 0.362689\n[4000]\ttraining's l1: 0.147402\tvalid_1's l1: 0.359949\nDid not meet early stopping. Best iteration is:\n[4000]\ttraining's l1: 0.147402\tvalid_1's l1: 0.359949\nFold 2 started at Tue Apr 25 21:30:46 2023\nTraining until validation scores don't improve for 200 rounds.\n[500]\ttraining's l1: 0.368446\tvalid_1's l1: 0.427147\n[1000]\ttraining's l1: 0.299634\tvalid_1's l1: 0.396955\n[1500]\ttraining's l1: 0.2566\tvalid_1's l1: 0.382741\n[2000]\ttraining's l1: 0.225408\tvalid_1's l1: 0.374009\n[2500]\ttraining's l1: 0.200296\tvalid_1's l1: 0.367855\n[3000]\ttraining's l1: 0.179691\tvalid_1's l1: 0.363625\n[3500]\ttraining's l1: 0.162501\tvalid_1's l1: 0.360435\n[4000]\ttraining's l1: 0.147567\tvalid_1's l1: 0.357836\nDid not meet early stopping. Best iteration is:\n[4000]\ttraining's l1: 0.147567\tvalid_1's l1: 0.357836\nFold 3 started at Tue Apr 25 21:33:58 2023\nTraining until validation scores don't improve for 200 rounds.\n[500]\ttraining's l1: 0.366935\tvalid_1's l1: 0.430403\n[1000]\ttraining's l1: 0.299151\tvalid_1's l1: 0.400685\n[1500]\ttraining's l1: 0.256418\tvalid_1's l1: 0.385493\n[2000]\ttraining's l1: 0.224639\tvalid_1's l1: 0.376209\n[2500]\ttraining's l1: 0.199572\tvalid_1's l1: 0.370015\n[3000]\ttraining's l1: 0.179173\tvalid_1's l1: 0.365688\n[3500]\ttraining's l1: 0.161886\tvalid_1's l1: 0.362301\n[4000]\ttraining's l1: 0.146906\tvalid_1's l1: 0.359833\nDid not meet early stopping. Best iteration is:\n[4000]\ttraining's l1: 0.146906\tvalid_1's l1: 0.359833\nFold 4 started at Tue Apr 25 21:37:12 2023\nTraining until validation scores don't improve for 200 rounds.\n[500]\ttraining's l1: 0.366213\tvalid_1's l1: 0.434145\n[1000]\ttraining's l1: 0.298732\tvalid_1's l1: 0.403636\n[1500]\ttraining's l1: 0.256555\tvalid_1's l1: 0.389182\n[2000]\ttraining's l1: 0.225006\tvalid_1's l1: 0.379628\n[2500]\ttraining's l1: 0.200216\tvalid_1's l1: 0.373261\n[3000]\ttraining's l1: 0.17972\tvalid_1's l1: 0.368804\n[3500]\ttraining's l1: 0.16199\tvalid_1's l1: 0.36539\n[4000]\ttraining's l1: 0.147192\tvalid_1's l1: 0.362884\nDid not meet early stopping. Best iteration is:\n[4000]\ttraining's l1: 0.147192\tvalid_1's l1: 0.362884\nFold 5 started at Tue Apr 25 21:40:27 2023\nTraining until validation scores don't improve for 200 rounds.\n[500]\ttraining's l1: 0.366936\tvalid_1's l1: 0.433723\n[1000]\ttraining's l1: 0.298362\tvalid_1's l1: 0.402258\n[1500]\ttraining's l1: 0.25583\tvalid_1's l1: 0.38761\n[2000]\ttraining's l1: 0.224362\tvalid_1's l1: 0.37827\n[2500]\ttraining's l1: 0.199557\tvalid_1's l1: 0.372353\n[3000]\ttraining's l1: 0.179211\tvalid_1's l1: 0.367846\n[3500]\ttraining's l1: 0.161949\tvalid_1's l1: 0.36449\n[4000]\ttraining's l1: 0.147129\tvalid_1's l1: 0.361921\nDid not meet early stopping. Best iteration is:\n[4000]\ttraining's l1: 0.147129\tvalid_1's l1: 0.361921\nCV mean score: -1.0203, std: 0.0049.\nTraining of type 1\nFold 1 started at Tue Apr 25 21:43:39 2023\nTraining until validation scores don't improve for 200 rounds.\n[500]\ttraining's l1: 0.341683\tvalid_1's l1: 0.636259\n[1000]\ttraining's l1: 0.198189\tvalid_1's l1: 0.611669\n[1500]\ttraining's l1: 0.121866\tvalid_1's l1: 0.605254\n[2000]\ttraining's l1: 0.0776513\tvalid_1's l1: 0.601923\n[2500]\ttraining's l1: 0.05081\tvalid_1's l1: 0.6003\n[3000]\ttraining's l1: 0.0344135\tvalid_1's l1: 0.599242\n[3500]\ttraining's l1: 0.023786\tvalid_1's l1: 0.598604\n[4000]\ttraining's l1: 0.0166329\tvalid_1's l1: 0.59819\nDid not meet early stopping. Best iteration is:\n[4000]\ttraining's l1: 0.0166329\tvalid_1's l1: 0.59819\nFold 2 started at Tue Apr 25 21:44:35 2023\nTraining until validation scores don't improve for 200 rounds.\n[500]\ttraining's l1: 0.346936\tvalid_1's l1: 0.64293\n[1000]\ttraining's l1: 0.1981\tvalid_1's l1: 0.617749\n[1500]\ttraining's l1: 0.120416\tvalid_1's l1: 0.609999\n[2000]\ttraining's l1: 0.0769142\tvalid_1's l1: 0.607409\n[2500]\ttraining's l1: 0.0506402\tvalid_1's l1: 0.605976\n[3000]\ttraining's l1: 0.0341526\tvalid_1's l1: 0.605206\n[3500]\ttraining's l1: 0.0235187\tvalid_1's l1: 0.604838\n[4000]\ttraining's l1: 0.0165403\tvalid_1's l1: 0.604543\nDid not meet early stopping. Best iteration is:\n[4000]\ttraining's l1: 0.0165403\tvalid_1's l1: 0.604543\nFold 3 started at Tue Apr 25 21:45:30 2023\nTraining until validation scores don't improve for 200 rounds.\n[500]\ttraining's l1: 0.352903\tvalid_1's l1: 0.644556\n[1000]\ttraining's l1: 0.1986\tvalid_1's l1: 0.621006\n[1500]\ttraining's l1: 0.120855\tvalid_1's l1: 0.615146\n[2000]\ttraining's l1: 0.0768814\tvalid_1's l1: 0.612506\n[2500]\ttraining's l1: 0.0507507\tvalid_1's l1: 0.611776\n[3000]\ttraining's l1: 0.0343856\tvalid_1's l1: 0.610859\nEarly stopping, best iteration is:\n[3228]\ttraining's l1: 0.0290078\tvalid_1's l1: 0.610662\nFold 4 started at Tue Apr 25 21:46:17 2023\nTraining until validation scores don't improve for 200 rounds.\n[500]\ttraining's l1: 0.347846\tvalid_1's l1: 0.629982\n[1000]\ttraining's l1: 0.201011\tvalid_1's l1: 0.605599\n[1500]\ttraining's l1: 0.123116\tvalid_1's l1: 0.599077\n[2000]\ttraining's l1: 0.0784966\tvalid_1's l1: 0.596211\n[2500]\ttraining's l1: 0.0513453\tvalid_1's l1: 0.59463\n[3000]\ttraining's l1: 0.0345801\tvalid_1's l1: 0.593429\n[3500]\ttraining's l1: 0.0238076\tvalid_1's l1: 0.592821\n[4000]\ttraining's l1: 0.0167411\tvalid_1's l1: 0.592483\nDid not meet early stopping. Best iteration is:\n[4000]\ttraining's l1: 0.0167411\tvalid_1's l1: 0.592483\nFold 5 started at Tue Apr 25 21:47:13 2023\nTraining until validation scores don't improve for 200 rounds.\n[500]\ttraining's l1: 0.344591\tvalid_1's l1: 0.642452\n[1000]\ttraining's l1: 0.197216\tvalid_1's l1: 0.615768\n[1500]\ttraining's l1: 0.120806\tvalid_1's l1: 0.607864\n[2000]\ttraining's l1: 0.0768138\tvalid_1's l1: 0.605209\n[2500]\ttraining's l1: 0.0502943\tvalid_1's l1: 0.603733\n[3000]\ttraining's l1: 0.0339404\tvalid_1's l1: 0.603258\n[3500]\ttraining's l1: 0.0233681\tvalid_1's l1: 0.602814\n[4000]\ttraining's l1: 0.0163834\tvalid_1's l1: 0.602527\nDid not meet early stopping. Best iteration is:\n[4000]\ttraining's l1: 0.0163834\tvalid_1's l1: 0.602527\nCV mean score: -0.5081, std: 0.0102.\nTraining of type 4\nFold 1 started at Tue Apr 25 21:48:09 2023\nTraining until validation scores don't improve for 200 rounds.\n[500]\ttraining's l1: 0.290345\tvalid_1's l1: 0.424555\n[1000]\ttraining's l1: 0.202395\tvalid_1's l1: 0.401517\n[1500]\ttraining's l1: 0.150333\tvalid_1's l1: 0.390796\n[2000]\ttraining's l1: 0.115342\tvalid_1's l1: 0.385308\n[2500]\ttraining's l1: 0.0905635\tvalid_1's l1: 0.381941\n[3000]\ttraining's l1: 0.0721293\tvalid_1's l1: 0.380164\n[3500]\ttraining's l1: 0.0582572\tvalid_1's l1: 0.379079\n[4000]\ttraining's l1: 0.0474519\tvalid_1's l1: 0.378147\nDid not meet early stopping. Best iteration is:\n[4000]\ttraining's l1: 0.0474519\tvalid_1's l1: 0.378147\nFold 2 started at Tue Apr 25 21:49:34 2023\nTraining until validation scores don't improve for 200 rounds.\n[500]\ttraining's l1: 0.29179\tvalid_1's l1: 0.430852\n[1000]\ttraining's l1: 0.201529\tvalid_1's l1: 0.404202\n[1500]\ttraining's l1: 0.149657\tvalid_1's l1: 0.394241\n[2000]\ttraining's l1: 0.115196\tvalid_1's l1: 0.389206\n[2500]\ttraining's l1: 0.0904307\tvalid_1's l1: 0.386266\n[3000]\ttraining's l1: 0.0719862\tvalid_1's l1: 0.384326\n[3500]\ttraining's l1: 0.0579928\tvalid_1's l1: 0.383421\n[4000]\ttraining's l1: 0.0471737\tvalid_1's l1: 0.382494\nDid not meet early stopping. Best iteration is:\n[4000]\ttraining's l1: 0.0471737\tvalid_1's l1: 0.382494\nFold 3 started at Tue Apr 25 21:51:00 2023\nTraining until validation scores don't improve for 200 rounds.\n[500]\ttraining's l1: 0.288498\tvalid_1's l1: 0.432785\n[1000]\ttraining's l1: 0.200717\tvalid_1's l1: 0.407403\n[1500]\ttraining's l1: 0.149333\tvalid_1's l1: 0.397426\n[2000]\ttraining's l1: 0.114335\tvalid_1's l1: 0.392358\n[2500]\ttraining's l1: 0.0896724\tvalid_1's l1: 0.38917\n[3000]\ttraining's l1: 0.0713574\tvalid_1's l1: 0.387498\n[3500]\ttraining's l1: 0.0575438\tvalid_1's l1: 0.386061\n[4000]\ttraining's l1: 0.046687\tvalid_1's l1: 0.385031\nDid not meet early stopping. Best iteration is:\n[4000]\ttraining's l1: 0.046687\tvalid_1's l1: 0.385031\nFold 4 started at Tue Apr 25 21:52:26 2023\nTraining until validation scores don't improve for 200 rounds.\n[500]\ttraining's l1: 0.28577\tvalid_1's l1: 0.427824\n[1000]\ttraining's l1: 0.199012\tvalid_1's l1: 0.403201\n[1500]\ttraining's l1: 0.147852\tvalid_1's l1: 0.393903\n[2000]\ttraining's l1: 0.11374\tvalid_1's l1: 0.389082\n[2500]\ttraining's l1: 0.0892115\tvalid_1's l1: 0.385938\n[3000]\ttraining's l1: 0.0712698\tvalid_1's l1: 0.383645\n[3500]\ttraining's l1: 0.0573987\tvalid_1's l1: 0.382415\n[4000]\ttraining's l1: 0.0467392\tvalid_1's l1: 0.381494\nDid not meet early stopping. Best iteration is:\n[4000]\ttraining's l1: 0.0467392\tvalid_1's l1: 0.381494\nFold 5 started at Tue Apr 25 21:53:52 2023\nTraining until validation scores don't improve for 200 rounds.\n[500]\ttraining's l1: 0.288654\tvalid_1's l1: 0.424171\n[1000]\ttraining's l1: 0.200784\tvalid_1's l1: 0.399558\n[1500]\ttraining's l1: 0.148978\tvalid_1's l1: 0.390268\n[2000]\ttraining's l1: 0.114572\tvalid_1's l1: 0.385065\n[2500]\ttraining's l1: 0.0897761\tvalid_1's l1: 0.382193\n[3000]\ttraining's l1: 0.0715062\tvalid_1's l1: 0.379987\n[3500]\ttraining's l1: 0.0576512\tvalid_1's l1: 0.378632\n[4000]\ttraining's l1: 0.0469496\tvalid_1's l1: 0.377704\nDid not meet early stopping. Best iteration is:\n[4000]\ttraining's l1: 0.0469496\tvalid_1's l1: 0.377704\nCV mean score: -0.9651, std: 0.0072.\nTraining of type 2\nFold 1 started at Tue Apr 25 21:55:19 2023\nTraining until validation scores don't improve for 200 rounds.\n[500]\ttraining's l1: 0.850643\tvalid_1's l1: 0.902521\n[1000]\ttraining's l1: 0.738308\tvalid_1's l1: 0.824028\n[1500]\ttraining's l1: 0.669661\tvalid_1's l1: 0.784514\n[2000]\ttraining's l1: 0.618696\tvalid_1's l1: 0.758425\n[2500]\ttraining's l1: 0.578499\tvalid_1's l1: 0.740397\n[3000]\ttraining's l1: 0.545061\tvalid_1's l1: 0.728145\n[3500]\ttraining's l1: 0.51498\tvalid_1's l1: 0.717243\n[4000]\ttraining's l1: 0.488487\tvalid_1's l1: 0.708701\nDid not meet early stopping. Best iteration is:\n[4000]\ttraining's l1: 0.488487\tvalid_1's l1: 0.708701\nFold 2 started at Tue Apr 25 22:02:59 2023\nTraining until validation scores don't improve for 200 rounds.\n[500]\ttraining's l1: 0.846606\tvalid_1's l1: 0.897031\n[1000]\ttraining's l1: 0.737223\tvalid_1's l1: 0.821105\n[1500]\ttraining's l1: 0.669639\tvalid_1's l1: 0.781888\n[2000]\ttraining's l1: 0.619888\tvalid_1's l1: 0.756924\n[2500]\ttraining's l1: 0.579066\tvalid_1's l1: 0.738948\n[3000]\ttraining's l1: 0.544236\tvalid_1's l1: 0.725165\n[3500]\ttraining's l1: 0.514558\tvalid_1's l1: 0.714156\n[4000]\ttraining's l1: 0.488168\tvalid_1's l1: 0.705271\nDid not meet early stopping. Best iteration is:\n[4000]\ttraining's l1: 0.488168\tvalid_1's l1: 0.705271\nFold 3 started at Tue Apr 25 22:10:35 2023\nTraining until validation scores don't improve for 200 rounds.\n[500]\ttraining's l1: 0.844347\tvalid_1's l1: 0.893595\n[1000]\ttraining's l1: 0.737214\tvalid_1's l1: 0.820667\n[1500]\ttraining's l1: 0.668825\tvalid_1's l1: 0.780974\n[2000]\ttraining's l1: 0.618545\tvalid_1's l1: 0.75619\n[2500]\ttraining's l1: 0.57794\tvalid_1's l1: 0.738556\n[3000]\ttraining's l1: 0.544255\tvalid_1's l1: 0.725536\n[3500]\ttraining's l1: 0.514371\tvalid_1's l1: 0.714599\n[4000]\ttraining's l1: 0.4879\tvalid_1's l1: 0.705973\nDid not meet early stopping. Best iteration is:\n[4000]\ttraining's l1: 0.4879\tvalid_1's l1: 0.705973\nFold 4 started at Tue Apr 25 22:18:04 2023\nTraining until validation scores don't improve for 200 rounds.\n[500]\ttraining's l1: 0.848861\tvalid_1's l1: 0.89465\n[1000]\ttraining's l1: 0.737585\tvalid_1's l1: 0.818362\n[1500]\ttraining's l1: 0.668975\tvalid_1's l1: 0.779782\n[2000]\ttraining's l1: 0.619009\tvalid_1's l1: 0.755641\n[2500]\ttraining's l1: 0.57761\tvalid_1's l1: 0.736709\n[3000]\ttraining's l1: 0.543301\tvalid_1's l1: 0.723785\n[3500]\ttraining's l1: 0.51411\tvalid_1's l1: 0.713801\n[4000]\ttraining's l1: 0.487274\tvalid_1's l1: 0.704845\nDid not meet early stopping. Best iteration is:\n[4000]\ttraining's l1: 0.487274\tvalid_1's l1: 0.704845\nFold 5 started at Tue Apr 25 22:25:37 2023\nTraining until validation scores don't improve for 200 rounds.\n[500]\ttraining's l1: 0.849712\tvalid_1's l1: 0.900357\n[1000]\ttraining's l1: 0.73713\tvalid_1's l1: 0.821255\n[1500]\ttraining's l1: 0.669596\tvalid_1's l1: 0.782287\n[2000]\ttraining's l1: 0.618216\tvalid_1's l1: 0.756868\n[2500]\ttraining's l1: 0.578808\tvalid_1's l1: 0.740343\n[3000]\ttraining's l1: 0.544335\tvalid_1's l1: 0.726476\n[3500]\ttraining's l1: 0.514376\tvalid_1's l1: 0.715569\n[4000]\ttraining's l1: 0.487893\tvalid_1's l1: 0.706591\nDid not meet early stopping. Best iteration is:\n[4000]\ttraining's l1: 0.487893\tvalid_1's l1: 0.706591\nCV mean score: -0.3478, std: 0.0019.\nTraining of type 6\nFold 1 started at Tue Apr 25 22:33:14 2023\nTraining until validation scores don't improve for 200 rounds.\n[500]\ttraining's l1: 0.444774\tvalid_1's l1: 0.487162\n[1000]\ttraining's l1: 0.374564\tvalid_1's l1: 0.447295\n[1500]\ttraining's l1: 0.329902\tvalid_1's l1: 0.426781\n[2000]\ttraining's l1: 0.297066\tvalid_1's l1: 0.41469\n[2500]\ttraining's l1: 0.270418\tvalid_1's l1: 0.406049\n[3000]\ttraining's l1: 0.248416\tvalid_1's l1: 0.399696\n[3500]\ttraining's l1: 0.229257\tvalid_1's l1: 0.395087\n[4000]\ttraining's l1: 0.212716\tvalid_1's l1: 0.391139\nDid not meet early stopping. Best iteration is:\n[4000]\ttraining's l1: 0.212716\tvalid_1's l1: 0.391139\nFold 2 started at Tue Apr 25 22:37:34 2023\nTraining until validation scores don't improve for 200 rounds.\n[500]\ttraining's l1: 0.444919\tvalid_1's l1: 0.490083\n[1000]\ttraining's l1: 0.372235\tvalid_1's l1: 0.447314\n[1500]\ttraining's l1: 0.328533\tvalid_1's l1: 0.427965\n[2000]\ttraining's l1: 0.295893\tvalid_1's l1: 0.415854\n[2500]\ttraining's l1: 0.269837\tvalid_1's l1: 0.407616\n[3000]\ttraining's l1: 0.247842\tvalid_1's l1: 0.401404\n[3500]\ttraining's l1: 0.228762\tvalid_1's l1: 0.396575\n[4000]\ttraining's l1: 0.212205\tvalid_1's l1: 0.392639\nDid not meet early stopping. Best iteration is:\n[4000]\ttraining's l1: 0.212205\tvalid_1's l1: 0.392639\nFold 3 started at Tue Apr 25 22:41:54 2023\nTraining until validation scores don't improve for 200 rounds.\n[500]\ttraining's l1: 0.444583\tvalid_1's l1: 0.489644\n[1000]\ttraining's l1: 0.37487\tvalid_1's l1: 0.448749\n[1500]\ttraining's l1: 0.329828\tvalid_1's l1: 0.427797\n[2000]\ttraining's l1: 0.296712\tvalid_1's l1: 0.415386\n[2500]\ttraining's l1: 0.270299\tvalid_1's l1: 0.406753\n[3000]\ttraining's l1: 0.248406\tvalid_1's l1: 0.400952\n[3500]\ttraining's l1: 0.229308\tvalid_1's l1: 0.395827\n[4000]\ttraining's l1: 0.212489\tvalid_1's l1: 0.391946\nDid not meet early stopping. Best iteration is:\n[4000]\ttraining's l1: 0.212489\tvalid_1's l1: 0.391946\nFold 4 started at Tue Apr 25 22:46:13 2023\nTraining until validation scores don't improve for 200 rounds.\n[500]\ttraining's l1: 0.444607\tvalid_1's l1: 0.492281\n[1000]\ttraining's l1: 0.373329\tvalid_1's l1: 0.450615\n[1500]\ttraining's l1: 0.329387\tvalid_1's l1: 0.430605\n[2000]\ttraining's l1: 0.296503\tvalid_1's l1: 0.417928\n[2500]\ttraining's l1: 0.270247\tvalid_1's l1: 0.409446\n[3000]\ttraining's l1: 0.248141\tvalid_1's l1: 0.403317\n[3500]\ttraining's l1: 0.229251\tvalid_1's l1: 0.398761\n[4000]\ttraining's l1: 0.212753\tvalid_1's l1: 0.395094\nDid not meet early stopping. Best iteration is:\n[4000]\ttraining's l1: 0.212753\tvalid_1's l1: 0.395094\nFold 5 started at Tue Apr 25 22:50:35 2023\nTraining until validation scores don't improve for 200 rounds.\n[500]\ttraining's l1: 0.445467\tvalid_1's l1: 0.49169\n[1000]\ttraining's l1: 0.373145\tvalid_1's l1: 0.449718\n[1500]\ttraining's l1: 0.328621\tvalid_1's l1: 0.429397\n[2000]\ttraining's l1: 0.29594\tvalid_1's l1: 0.417298\n[2500]\ttraining's l1: 0.269382\tvalid_1's l1: 0.40818\n[3000]\ttraining's l1: 0.247629\tvalid_1's l1: 0.402347\n[3500]\ttraining's l1: 0.228884\tvalid_1's l1: 0.397557\n[4000]\ttraining's l1: 0.212587\tvalid_1's l1: 0.393625\nDid not meet early stopping. Best iteration is:\n[4000]\ttraining's l1: 0.212587\tvalid_1's l1: 0.393625\nCV mean score: -0.9342, std: 0.0035.\nTraining of type 5\nFold 1 started at Tue Apr 25 22:55:00 2023\nTraining until validation scores don't improve for 200 rounds.\n[500]\ttraining's l1: 0.942965\tvalid_1's l1: 0.982916\n[1000]\ttraining's l1: 0.82454\tvalid_1's l1: 0.893272\n[1500]\ttraining's l1: 0.751172\tvalid_1's l1: 0.84403\n[2000]\ttraining's l1: 0.699149\tvalid_1's l1: 0.813884\n[2500]\ttraining's l1: 0.658249\tvalid_1's l1: 0.792493\n[3000]\ttraining's l1: 0.623699\tvalid_1's l1: 0.775921\n[3500]\ttraining's l1: 0.593213\tvalid_1's l1: 0.762221\n[4000]\ttraining's l1: 0.566582\tvalid_1's l1: 0.751343\nDid not meet early stopping. Best iteration is:\n[4000]\ttraining's l1: 0.566582\tvalid_1's l1: 0.751343\nFold 2 started at Tue Apr 25 23:04:48 2023\nTraining until validation scores don't improve for 200 rounds.\n[500]\ttraining's l1: 0.940905\tvalid_1's l1: 0.979577\n[1000]\ttraining's l1: 0.825028\tvalid_1's l1: 0.892487\n[1500]\ttraining's l1: 0.754501\tvalid_1's l1: 0.846438\n[2000]\ttraining's l1: 0.701566\tvalid_1's l1: 0.8152\n[2500]\ttraining's l1: 0.659891\tvalid_1's l1: 0.793076\n[3000]\ttraining's l1: 0.624987\tvalid_1's l1: 0.776519\n[3500]\ttraining's l1: 0.594954\tvalid_1's l1: 0.763343\n[4000]\ttraining's l1: 0.56807\tvalid_1's l1: 0.752213\nDid not meet early stopping. Best iteration is:\n[4000]\ttraining's l1: 0.56807\tvalid_1's l1: 0.752213\nFold 3 started at Tue Apr 25 23:14:41 2023\nTraining until validation scores don't improve for 200 rounds.\n[500]\ttraining's l1: 0.9396\tvalid_1's l1: 0.980126\n[1000]\ttraining's l1: 0.824677\tvalid_1's l1: 0.892415\n[1500]\ttraining's l1: 0.751955\tvalid_1's l1: 0.84363\n[2000]\ttraining's l1: 0.701049\tvalid_1's l1: 0.814607\n[2500]\ttraining's l1: 0.65982\tvalid_1's l1: 0.793373\n[3000]\ttraining's l1: 0.62469\tvalid_1's l1: 0.776164\n[3500]\ttraining's l1: 0.594402\tvalid_1's l1: 0.763017\n[4000]\ttraining's l1: 0.567186\tvalid_1's l1: 0.751478\nDid not meet early stopping. Best iteration is:\n[4000]\ttraining's l1: 0.567186\tvalid_1's l1: 0.751478\nFold 4 started at Tue Apr 25 23:24:23 2023\nTraining until validation scores don't improve for 200 rounds.\n[500]\ttraining's l1: 0.940608\tvalid_1's l1: 0.980839\n[1000]\ttraining's l1: 0.822917\tvalid_1's l1: 0.892265\n[1500]\ttraining's l1: 0.750942\tvalid_1's l1: 0.84413\n[2000]\ttraining's l1: 0.699354\tvalid_1's l1: 0.81436\n[2500]\ttraining's l1: 0.65784\tvalid_1's l1: 0.792138\n[3000]\ttraining's l1: 0.623221\tvalid_1's l1: 0.775699\n[3500]\ttraining's l1: 0.593319\tvalid_1's l1: 0.762566\n[4000]\ttraining's l1: 0.566542\tvalid_1's l1: 0.751607\nDid not meet early stopping. Best iteration is:\n[4000]\ttraining's l1: 0.566542\tvalid_1's l1: 0.751607\nFold 5 started at Tue Apr 25 23:34:08 2023\nTraining until validation scores don't improve for 200 rounds.\n[500]\ttraining's l1: 0.941043\tvalid_1's l1: 0.982658\n[1000]\ttraining's l1: 0.821411\tvalid_1's l1: 0.890592\n[1500]\ttraining's l1: 0.750663\tvalid_1's l1: 0.8448\n[2000]\ttraining's l1: 0.698587\tvalid_1's l1: 0.814813\n[2500]\ttraining's l1: 0.656939\tvalid_1's l1: 0.792876\n[3000]\ttraining's l1: 0.621926\tvalid_1's l1: 0.775745\n[3500]\ttraining's l1: 0.591614\tvalid_1's l1: 0.762193\n[4000]\ttraining's l1: 0.56502\tvalid_1's l1: 0.751471\nDid not meet early stopping. Best iteration is:\n[4000]\ttraining's l1: 0.56502\tvalid_1's l1: 0.751471\nCV mean score: -0.2855, std: 0.0004.\nTraining of type 7\nFold 1 started at Tue Apr 25 23:44:00 2023\nTraining until validation scores don't improve for 200 rounds.\n[500]\ttraining's l1: 0.2069\tvalid_1's l1: 0.28004\n[1000]\ttraining's l1: 0.150718\tvalid_1's l1: 0.261867\n[1500]\ttraining's l1: 0.117016\tvalid_1's l1: 0.253568\n[2000]\ttraining's l1: 0.0936445\tvalid_1's l1: 0.249106\n[2500]\ttraining's l1: 0.0765257\tvalid_1's l1: 0.246158\n[3000]\ttraining's l1: 0.0632271\tvalid_1's l1: 0.244012\n[3500]\ttraining's l1: 0.05283\tvalid_1's l1: 0.24274\n[4000]\ttraining's l1: 0.0444052\tvalid_1's l1: 0.241827\nDid not meet early stopping. Best iteration is:\n[4000]\ttraining's l1: 0.0444052\tvalid_1's l1: 0.241827\nFold 2 started at Tue Apr 25 23:45:46 2023\nTraining until validation scores don't improve for 200 rounds.\n[500]\ttraining's l1: 0.205878\tvalid_1's l1: 0.283883\n[1000]\ttraining's l1: 0.150221\tvalid_1's l1: 0.265124\n[1500]\ttraining's l1: 0.116811\tvalid_1's l1: 0.257047\n[2000]\ttraining's l1: 0.093602\tvalid_1's l1: 0.252374\n[2500]\ttraining's l1: 0.0763522\tvalid_1's l1: 0.249307\n[3000]\ttraining's l1: 0.0631451\tvalid_1's l1: 0.247504\n[3500]\ttraining's l1: 0.0526528\tvalid_1's l1: 0.246152\n[4000]\ttraining's l1: 0.0443075\tvalid_1's l1: 0.245183\nDid not meet early stopping. Best iteration is:\n[4000]\ttraining's l1: 0.0443075\tvalid_1's l1: 0.245183\nFold 3 started at Tue Apr 25 23:47:32 2023\nTraining until validation scores don't improve for 200 rounds.\n[500]\ttraining's l1: 0.205829\tvalid_1's l1: 0.278743\n[1000]\ttraining's l1: 0.150121\tvalid_1's l1: 0.26177\n[1500]\ttraining's l1: 0.116761\tvalid_1's l1: 0.253688\n[2000]\ttraining's l1: 0.0934152\tvalid_1's l1: 0.249423\n[2500]\ttraining's l1: 0.0761116\tvalid_1's l1: 0.246592\n[3000]\ttraining's l1: 0.0629733\tvalid_1's l1: 0.244825\n[3500]\ttraining's l1: 0.0525702\tvalid_1's l1: 0.24347\n[4000]\ttraining's l1: 0.0441972\tvalid_1's l1: 0.242526\nDid not meet early stopping. Best iteration is:\n[4000]\ttraining's l1: 0.0441972\tvalid_1's l1: 0.242526\nFold 4 started at Tue Apr 25 23:49:18 2023\nTraining until validation scores don't improve for 200 rounds.\n[500]\ttraining's l1: 0.206012\tvalid_1's l1: 0.283648\n[1000]\ttraining's l1: 0.150823\tvalid_1's l1: 0.265299\n[1500]\ttraining's l1: 0.11721\tvalid_1's l1: 0.256998\n[2000]\ttraining's l1: 0.0938746\tvalid_1's l1: 0.252528\n[2500]\ttraining's l1: 0.0764899\tvalid_1's l1: 0.249319\n[3000]\ttraining's l1: 0.0632757\tvalid_1's l1: 0.247147\n[3500]\ttraining's l1: 0.0528367\tvalid_1's l1: 0.245861\n[4000]\ttraining's l1: 0.0444484\tvalid_1's l1: 0.244845\nDid not meet early stopping. Best iteration is:\n[4000]\ttraining's l1: 0.0444484\tvalid_1's l1: 0.244845\nFold 5 started at Tue Apr 25 23:51:03 2023\nTraining until validation scores don't improve for 200 rounds.\n[500]\ttraining's l1: 0.205933\tvalid_1's l1: 0.279139\n[1000]\ttraining's l1: 0.150293\tvalid_1's l1: 0.261545\n[1500]\ttraining's l1: 0.1165\tvalid_1's l1: 0.253841\n[2000]\ttraining's l1: 0.0933828\tvalid_1's l1: 0.249587\n[2500]\ttraining's l1: 0.0760228\tvalid_1's l1: 0.246907\n[3000]\ttraining's l1: 0.0629147\tvalid_1's l1: 0.245005\n[3500]\ttraining's l1: 0.0525008\tvalid_1's l1: 0.243738\n[4000]\ttraining's l1: 0.0441334\tvalid_1's l1: 0.242645\nDid not meet early stopping. Best iteration is:\n[4000]\ttraining's l1: 0.0441334\tvalid_1's l1: 0.242645\nCV mean score: -1.4130, std: 0.0055.\n","output_type":"stream"}]},{"cell_type":"code","source":"X['oof_fc'] = X_short['oof']\nX_test['oof_fc'] = X_short_test['prediction']","metadata":{"execution":{"iopub.status.busy":"2023-04-25T23:52:51.089160Z","iopub.execute_input":"2023-04-25T23:52:51.089738Z","iopub.status.idle":"2023-04-25T23:52:51.154263Z","shell.execute_reply.started":"2023-04-25T23:52:51.089675Z","shell.execute_reply":"2023-04-25T23:52:51.153348Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"code","source":"\ngood_columns = ['type','oof_fc',\n 'bond_lengths_mean_y',\n 'bond_lengths_std_y',\n 'bond_lengths_mean_x',\n 'molecule_atom_index_0_dist_min_div',\n 'molecule_atom_index_0_dist_std_div',\n 'molecule_atom_index_0_dist_mean',\n 'molecule_atom_index_0_dist_max',\n 'dist_y',\n 'molecule_atom_index_1_dist_std_diff',\n 'z_0',\n 'molecule_type_dist_min',\n 'molecule_atom_index_0_y_1_mean_div',\n 'dist_x',\n 'x_0',\n 'y_0',\n 'molecule_type_dist_std',\n 'molecule_atom_index_0_y_1_std',\n 'molecule_dist_mean',\n 'molecule_atom_index_0_dist_std_diff',\n 'dist_z',\n 'molecule_atom_index_0_dist_std',\n 'molecule_atom_index_0_x_1_std',\n 'molecule_type_dist_std_diff',\n 'molecule_type_0_dist_std',\n 'dist',\n 'molecule_atom_index_0_dist_mean_diff',\n 'molecule_atom_index_1_dist_min_div',\n 'molecule_atom_index_1_dist_mean_diff',\n 'y_1',\n 'molecule_type_dist_mean_div',\n 'molecule_dist_max',\n 'molecule_atom_index_0_dist_mean_div',\n 'z_1',\n 'molecule_atom_index_0_z_1_std',\n 'molecule_atom_index_1_dist_mean_div',\n 'molecule_atom_index_1_dist_min_diff',\n 'molecule_atom_index_1_dist_mean',\n 'molecule_atom_index_1_dist_min',\n 'molecule_atom_index_1_dist_max',\n 'molecule_type_0_dist_std_diff',\n 'molecule_atom_index_0_dist_min_diff',\n 'molecule_type_dist_mean_diff',\n 'x_1',\n 'molecule_atom_index_0_y_1_max',\n 'molecule_atom_index_0_y_1_mean_diff',\n 'molecule_atom_1_dist_std_diff',\n 'molecule_atom_index_0_y_1_mean',\n 'molecule_atom_1_dist_std',\n 'molecule_type_dist_max']\n\nX = X[good_columns].copy()\nX_test = X_test[good_columns].copy()","metadata":{"execution":{"iopub.status.busy":"2023-04-25T23:52:51.155568Z","iopub.execute_input":"2023-04-25T23:52:51.155982Z","iopub.status.idle":"2023-04-25T23:52:54.814938Z","shell.execute_reply.started":"2023-04-25T23:52:51.155914Z","shell.execute_reply":"2023-04-25T23:52:54.813974Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"markdown","source":"# Checking Best Feature for Final Model","metadata":{}},{"cell_type":"code","source":"params = {'num_leaves': 50,\n          'min_child_samples': 79,\n          'min_data_in_leaf': 100,\n          'objective': 'regression',\n          'max_depth': 9,\n          'learning_rate': 0.2,\n          \"boosting_type\": \"gbdt\",\n          \"subsample_freq\": 1,\n          \"subsample\": 0.9,\n          \"bagging_seed\": 11,\n          \"metric\": 'mae',\n          \"verbosity\": -1,\n          'reg_alpha': 0.1,\n          'reg_lambda': 0.3,\n          'colsample_bytree': 1.0\n         }\n#result_dict_lgb2 = train_model_regression(X=X, X_test=X_test, y=y, params=params, folds=folds, model_type='lgb', eval_metric='group_mae', plot_feature_importance=True,\n#                                                      verbose=500, early_stopping_rounds=200, n_estimators=n_estimators_default)\n","metadata":{"execution":{"iopub.status.busy":"2023-04-25T23:52:54.816585Z","iopub.execute_input":"2023-04-25T23:52:54.816991Z","iopub.status.idle":"2023-04-25T23:52:54.824750Z","shell.execute_reply.started":"2023-04-25T23:52:54.816913Z","shell.execute_reply":"2023-04-25T23:52:54.823938Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"code","source":"#Best Features? \n''' \nfeature_importance = result_dict_lgb2['feature_importance']\nbest_features = feature_importance[['feature','importance']].groupby(['feature']).mean().sort_values(\n        by='importance',ascending=False).iloc[:50,0:0].index.tolist()\nbest_features'''","metadata":{"execution":{"iopub.status.busy":"2023-04-25T23:52:54.825889Z","iopub.execute_input":"2023-04-25T23:52:54.826309Z","iopub.status.idle":"2023-04-25T23:52:54.845297Z","shell.execute_reply.started":"2023-04-25T23:52:54.826246Z","shell.execute_reply":"2023-04-25T23:52:54.844177Z"},"trusted":true},"execution_count":31,"outputs":[{"execution_count":31,"output_type":"execute_result","data":{"text/plain":"\" \\nfeature_importance = result_dict_lgb2['feature_importance']\\nbest_features = feature_importance[['feature','importance']].groupby(['feature']).mean().sort_values(\\n        by='importance',ascending=False).iloc[:50,0:0].index.tolist()\\nbest_features\""},"metadata":{}}]},{"cell_type":"markdown","source":"<a id=\"id6\"></a> <br> \n# **6. Final Model** ","metadata":{}},{"cell_type":"markdown","source":"## Training models for each type","metadata":{}},{"cell_type":"code","source":"X_short = pd.DataFrame({'ind': list(X.index), 'type': X['type'].values, 'oof': [0] * len(X), 'target': y.values})\nX_short_test = pd.DataFrame({'ind': list(X_test.index), 'type': X_test['type'].values, 'prediction': [0] * len(X_test)})\nfor t in X['type'].unique():\n    print(f'Training of type {t}')\n    X_t = X.loc[X['type'] == t]\n    X_test_t = X_test.loc[X_test['type'] == t]\n    y_t = X_short.loc[X_short['type'] == t, 'target']\n    result_dict_lgb3 = train_model_regression(X=X_t, X_test=X_test_t, y=y_t, params=params, folds=folds, model_type='lgb', eval_metric='group_mae', plot_feature_importance=False,\n                                                      verbose=500, early_stopping_rounds=200, n_estimators=n_estimators_default)\n    X_short.loc[X_short['type'] == t, 'oof'] = result_dict_lgb3['oof']\n    X_short_test.loc[X_short_test['type'] == t, 'prediction'] = result_dict_lgb3['prediction']","metadata":{"execution":{"iopub.status.busy":"2023-04-25T23:52:54.846905Z","iopub.execute_input":"2023-04-25T23:52:54.847180Z","iopub.status.idle":"2023-04-26T02:28:00.513680Z","shell.execute_reply.started":"2023-04-25T23:52:54.847112Z","shell.execute_reply":"2023-04-26T02:28:00.512744Z"},"trusted":true},"execution_count":32,"outputs":[{"name":"stdout","text":"Training of type 0\nFold 1 started at Tue Apr 25 23:52:59 2023\nTraining until validation scores don't improve for 200 rounds.\n[500]\ttraining's l1: 1.31988\tvalid_1's l1: 1.43757\n[1000]\ttraining's l1: 1.2239\tvalid_1's l1: 1.43533\n[1500]\ttraining's l1: 1.14024\tvalid_1's l1: 1.43107\n[2000]\ttraining's l1: 1.06581\tvalid_1's l1: 1.42584\n[2500]\ttraining's l1: 0.998435\tvalid_1's l1: 1.4206\n[3000]\ttraining's l1: 0.937594\tvalid_1's l1: 1.4157\n[3500]\ttraining's l1: 0.881737\tvalid_1's l1: 1.40985\n[4000]\ttraining's l1: 0.831063\tvalid_1's l1: 1.40513\nDid not meet early stopping. Best iteration is:\n[4000]\ttraining's l1: 0.831063\tvalid_1's l1: 1.40513\nFold 2 started at Tue Apr 25 23:57:52 2023\nTraining until validation scores don't improve for 200 rounds.\n[500]\ttraining's l1: 1.32003\tvalid_1's l1: 1.44014\n[1000]\ttraining's l1: 1.22298\tvalid_1's l1: 1.4382\n[1500]\ttraining's l1: 1.13901\tvalid_1's l1: 1.43438\n[2000]\ttraining's l1: 1.06415\tvalid_1's l1: 1.43032\n[2500]\ttraining's l1: 0.997043\tvalid_1's l1: 1.42436\n[3000]\ttraining's l1: 0.935871\tvalid_1's l1: 1.42009\n[3500]\ttraining's l1: 0.880926\tvalid_1's l1: 1.41488\n[4000]\ttraining's l1: 0.830031\tvalid_1's l1: 1.40967\nDid not meet early stopping. Best iteration is:\n[4000]\ttraining's l1: 0.830031\tvalid_1's l1: 1.40967\nFold 3 started at Wed Apr 26 00:02:50 2023\nTraining until validation scores don't improve for 200 rounds.\n[500]\ttraining's l1: 1.3191\tvalid_1's l1: 1.43588\n[1000]\ttraining's l1: 1.2209\tvalid_1's l1: 1.4328\n[1500]\ttraining's l1: 1.13765\tvalid_1's l1: 1.43107\n[2000]\ttraining's l1: 1.06308\tvalid_1's l1: 1.4268\n[2500]\ttraining's l1: 0.995705\tvalid_1's l1: 1.42162\n[3000]\ttraining's l1: 0.934159\tvalid_1's l1: 1.41652\n[3500]\ttraining's l1: 0.878296\tvalid_1's l1: 1.41024\n[4000]\ttraining's l1: 0.827625\tvalid_1's l1: 1.40563\nDid not meet early stopping. Best iteration is:\n[4000]\ttraining's l1: 0.827625\tvalid_1's l1: 1.40563\nFold 4 started at Wed Apr 26 00:07:36 2023\nTraining until validation scores don't improve for 200 rounds.\nEarly stopping, best iteration is:\n[293]\ttraining's l1: 1.36382\tvalid_1's l1: 1.43805\nFold 5 started at Wed Apr 26 00:08:13 2023\nTraining until validation scores don't improve for 200 rounds.\n[500]\ttraining's l1: 1.31767\tvalid_1's l1: 1.43802\n[1000]\ttraining's l1: 1.22105\tvalid_1's l1: 1.43537\n[1500]\ttraining's l1: 1.13639\tvalid_1's l1: 1.43195\n[2000]\ttraining's l1: 1.06194\tvalid_1's l1: 1.42735\n[2500]\ttraining's l1: 0.994436\tvalid_1's l1: 1.42228\n[3000]\ttraining's l1: 0.93429\tvalid_1's l1: 1.41765\n[3500]\ttraining's l1: 0.878859\tvalid_1's l1: 1.41295\n[4000]\ttraining's l1: 0.828331\tvalid_1's l1: 1.40827\nDid not meet early stopping. Best iteration is:\n[4000]\ttraining's l1: 0.828331\tvalid_1's l1: 1.40827\nCV mean score: 0.3459, std: 0.0088.\nTraining of type 3\nFold 1 started at Wed Apr 26 00:13:05 2023\nTraining until validation scores don't improve for 200 rounds.\n[500]\ttraining's l1: 0.292532\tvalid_1's l1: 0.344614\n[1000]\ttraining's l1: 0.25445\tvalid_1's l1: 0.341641\n[1500]\ttraining's l1: 0.224827\tvalid_1's l1: 0.338946\n[2000]\ttraining's l1: 0.200499\tvalid_1's l1: 0.33671\n[2500]\ttraining's l1: 0.179865\tvalid_1's l1: 0.334118\n[3000]\ttraining's l1: 0.162442\tvalid_1's l1: 0.331917\n[3500]\ttraining's l1: 0.147349\tvalid_1's l1: 0.330452\n[4000]\ttraining's l1: 0.134224\tvalid_1's l1: 0.329316\nDid not meet early stopping. Best iteration is:\n[4000]\ttraining's l1: 0.134224\tvalid_1's l1: 0.329316\nFold 2 started at Wed Apr 26 00:16:25 2023\nTraining until validation scores don't improve for 200 rounds.\n[500]\ttraining's l1: 0.293127\tvalid_1's l1: 0.342828\n[1000]\ttraining's l1: 0.2549\tvalid_1's l1: 0.339863\n[1500]\ttraining's l1: 0.225151\tvalid_1's l1: 0.336754\n[2000]\ttraining's l1: 0.200782\tvalid_1's l1: 0.334296\n[2500]\ttraining's l1: 0.180205\tvalid_1's l1: 0.332123\n[3000]\ttraining's l1: 0.162573\tvalid_1's l1: 0.330226\n[3500]\ttraining's l1: 0.147486\tvalid_1's l1: 0.328484\n[4000]\ttraining's l1: 0.134279\tvalid_1's l1: 0.326925\nDid not meet early stopping. Best iteration is:\n[4000]\ttraining's l1: 0.134279\tvalid_1's l1: 0.326925\nFold 3 started at Wed Apr 26 00:19:40 2023\nTraining until validation scores don't improve for 200 rounds.\n[500]\ttraining's l1: 0.293836\tvalid_1's l1: 0.344317\n[1000]\ttraining's l1: 0.255377\tvalid_1's l1: 0.340732\n[1500]\ttraining's l1: 0.225469\tvalid_1's l1: 0.337906\n[2000]\ttraining's l1: 0.200567\tvalid_1's l1: 0.335365\n[2500]\ttraining's l1: 0.18013\tvalid_1's l1: 0.333101\n[3000]\ttraining's l1: 0.162575\tvalid_1's l1: 0.331419\n[3500]\ttraining's l1: 0.14734\tvalid_1's l1: 0.329758\n[4000]\ttraining's l1: 0.134098\tvalid_1's l1: 0.328322\nDid not meet early stopping. Best iteration is:\n[4000]\ttraining's l1: 0.134098\tvalid_1's l1: 0.328322\nFold 4 started at Wed Apr 26 00:22:56 2023\nTraining until validation scores don't improve for 200 rounds.\n[500]\ttraining's l1: 0.292474\tvalid_1's l1: 0.347596\n[1000]\ttraining's l1: 0.254362\tvalid_1's l1: 0.344747\n[1500]\ttraining's l1: 0.22499\tvalid_1's l1: 0.341754\n[2000]\ttraining's l1: 0.200967\tvalid_1's l1: 0.339758\n[2500]\ttraining's l1: 0.180187\tvalid_1's l1: 0.33729\n[3000]\ttraining's l1: 0.162672\tvalid_1's l1: 0.335088\n[3500]\ttraining's l1: 0.14723\tvalid_1's l1: 0.33323\n[4000]\ttraining's l1: 0.133889\tvalid_1's l1: 0.33156\nDid not meet early stopping. Best iteration is:\n[4000]\ttraining's l1: 0.133889\tvalid_1's l1: 0.33156\nFold 5 started at Wed Apr 26 00:26:11 2023\nTraining until validation scores don't improve for 200 rounds.\n[500]\ttraining's l1: 0.291818\tvalid_1's l1: 0.345473\n[1000]\ttraining's l1: 0.25397\tvalid_1's l1: 0.342465\n[1500]\ttraining's l1: 0.224238\tvalid_1's l1: 0.339678\n[2000]\ttraining's l1: 0.200073\tvalid_1's l1: 0.337508\n[2500]\ttraining's l1: 0.179671\tvalid_1's l1: 0.335408\n[3000]\ttraining's l1: 0.162294\tvalid_1's l1: 0.333016\n[3500]\ttraining's l1: 0.14701\tvalid_1's l1: 0.331002\n[4000]\ttraining's l1: 0.133911\tvalid_1's l1: 0.329396\nDid not meet early stopping. Best iteration is:\n[4000]\ttraining's l1: 0.133911\tvalid_1's l1: 0.329396\nCV mean score: -1.1114, std: 0.0046.\nTraining of type 1\nFold 1 started at Wed Apr 26 00:29:28 2023\nTraining until validation scores don't improve for 200 rounds.\nEarly stopping, best iteration is:\n[26]\ttraining's l1: 0.561538\tvalid_1's l1: 0.585705\nFold 2 started at Wed Apr 26 00:29:32 2023\nTraining until validation scores don't improve for 200 rounds.\nEarly stopping, best iteration is:\n[31]\ttraining's l1: 0.554822\tvalid_1's l1: 0.589215\nFold 3 started at Wed Apr 26 00:29:34 2023\nTraining until validation scores don't improve for 200 rounds.\nEarly stopping, best iteration is:\n[26]\ttraining's l1: 0.558461\tvalid_1's l1: 0.597043\nFold 4 started at Wed Apr 26 00:29:37 2023\nTraining until validation scores don't improve for 200 rounds.\nEarly stopping, best iteration is:\n[26]\ttraining's l1: 0.561656\tvalid_1's l1: 0.58246\nFold 5 started at Wed Apr 26 00:29:40 2023\nTraining until validation scores don't improve for 200 rounds.\nEarly stopping, best iteration is:\n[28]\ttraining's l1: 0.556591\tvalid_1's l1: 0.590568\nCV mean score: -0.5294, std: 0.0083.\nTraining of type 4\nFold 1 started at Wed Apr 26 00:29:42 2023\nTraining until validation scores don't improve for 200 rounds.\n[500]\ttraining's l1: 0.21829\tvalid_1's l1: 0.320352\n[1000]\ttraining's l1: 0.156504\tvalid_1's l1: 0.313839\n[1500]\ttraining's l1: 0.117132\tvalid_1's l1: 0.31012\n[2000]\ttraining's l1: 0.0897894\tvalid_1's l1: 0.307842\n[2500]\ttraining's l1: 0.0701065\tvalid_1's l1: 0.305914\n[3000]\ttraining's l1: 0.0555646\tvalid_1's l1: 0.304971\n[3500]\ttraining's l1: 0.0446004\tvalid_1's l1: 0.304063\n[4000]\ttraining's l1: 0.0360818\tvalid_1's l1: 0.303321\nDid not meet early stopping. Best iteration is:\n[4000]\ttraining's l1: 0.0360818\tvalid_1's l1: 0.303321\nFold 2 started at Wed Apr 26 00:31:10 2023\nTraining until validation scores don't improve for 200 rounds.\n[500]\ttraining's l1: 0.218642\tvalid_1's l1: 0.323796\n[1000]\ttraining's l1: 0.156158\tvalid_1's l1: 0.317371\n[1500]\ttraining's l1: 0.11625\tvalid_1's l1: 0.313608\n[2000]\ttraining's l1: 0.0891179\tvalid_1's l1: 0.311244\n[2500]\ttraining's l1: 0.069642\tvalid_1's l1: 0.309608\n[3000]\ttraining's l1: 0.0551258\tvalid_1's l1: 0.308364\n[3500]\ttraining's l1: 0.0441546\tvalid_1's l1: 0.307421\n[4000]\ttraining's l1: 0.0357022\tvalid_1's l1: 0.30676\nDid not meet early stopping. Best iteration is:\n[4000]\ttraining's l1: 0.0357022\tvalid_1's l1: 0.30676\nFold 3 started at Wed Apr 26 00:32:38 2023\nTraining until validation scores don't improve for 200 rounds.\n[500]\ttraining's l1: 0.216435\tvalid_1's l1: 0.328357\n[1000]\ttraining's l1: 0.154828\tvalid_1's l1: 0.322285\n[1500]\ttraining's l1: 0.115459\tvalid_1's l1: 0.317829\n[2000]\ttraining's l1: 0.0884518\tvalid_1's l1: 0.315289\n[2500]\ttraining's l1: 0.069024\tvalid_1's l1: 0.313723\n[3000]\ttraining's l1: 0.0547875\tvalid_1's l1: 0.312766\n[3500]\ttraining's l1: 0.0439251\tvalid_1's l1: 0.311934\n[4000]\ttraining's l1: 0.0356394\tvalid_1's l1: 0.311295\nDid not meet early stopping. Best iteration is:\n[4000]\ttraining's l1: 0.0356394\tvalid_1's l1: 0.311295\nFold 4 started at Wed Apr 26 00:34:06 2023\nTraining until validation scores don't improve for 200 rounds.\n[500]\ttraining's l1: 0.21579\tvalid_1's l1: 0.325211\n[1000]\ttraining's l1: 0.153697\tvalid_1's l1: 0.31888\n[1500]\ttraining's l1: 0.114645\tvalid_1's l1: 0.314858\n[2000]\ttraining's l1: 0.0879083\tvalid_1's l1: 0.312016\n[2500]\ttraining's l1: 0.0686739\tvalid_1's l1: 0.310071\n[3000]\ttraining's l1: 0.0545026\tvalid_1's l1: 0.308884\n[3500]\ttraining's l1: 0.0438014\tvalid_1's l1: 0.307826\n[4000]\ttraining's l1: 0.0355947\tvalid_1's l1: 0.307157\nDid not meet early stopping. Best iteration is:\n[4000]\ttraining's l1: 0.0355947\tvalid_1's l1: 0.307157\nFold 5 started at Wed Apr 26 00:35:33 2023\nTraining until validation scores don't improve for 200 rounds.\n[500]\ttraining's l1: 0.217081\tvalid_1's l1: 0.317034\n[1000]\ttraining's l1: 0.156495\tvalid_1's l1: 0.313125\n[1500]\ttraining's l1: 0.116281\tvalid_1's l1: 0.30848\n[2000]\ttraining's l1: 0.0891772\tvalid_1's l1: 0.305966\n[2500]\ttraining's l1: 0.0696497\tvalid_1's l1: 0.304329\n[3000]\ttraining's l1: 0.0552743\tvalid_1's l1: 0.303332\n[3500]\ttraining's l1: 0.0442986\tvalid_1's l1: 0.302519\n[4000]\ttraining's l1: 0.0359062\tvalid_1's l1: 0.301975\nDid not meet early stopping. Best iteration is:\n[4000]\ttraining's l1: 0.0359062\tvalid_1's l1: 0.301975\nCV mean score: -1.1839, std: 0.0106.\nTraining of type 2\nFold 1 started at Wed Apr 26 00:37:01 2023\nTraining until validation scores don't improve for 200 rounds.\n[500]\ttraining's l1: 0.612813\tvalid_1's l1: 0.652346\n[1000]\ttraining's l1: 0.571913\tvalid_1's l1: 0.64167\n[1500]\ttraining's l1: 0.538521\tvalid_1's l1: 0.634669\n[2000]\ttraining's l1: 0.509571\tvalid_1's l1: 0.629212\n[2500]\ttraining's l1: 0.482795\tvalid_1's l1: 0.623694\n[3000]\ttraining's l1: 0.459047\tvalid_1's l1: 0.619181\n[3500]\ttraining's l1: 0.437327\tvalid_1's l1: 0.61529\n[4000]\ttraining's l1: 0.417381\tvalid_1's l1: 0.611773\nDid not meet early stopping. Best iteration is:\n[4000]\ttraining's l1: 0.417381\tvalid_1's l1: 0.611773\nFold 2 started at Wed Apr 26 00:44:24 2023\nTraining until validation scores don't improve for 200 rounds.\n[500]\ttraining's l1: 0.614498\tvalid_1's l1: 0.650792\n[1000]\ttraining's l1: 0.572277\tvalid_1's l1: 0.638491\n[1500]\ttraining's l1: 0.538492\tvalid_1's l1: 0.630915\n[2000]\ttraining's l1: 0.510221\tvalid_1's l1: 0.626107\n[2500]\ttraining's l1: 0.483217\tvalid_1's l1: 0.620375\n[3000]\ttraining's l1: 0.459641\tvalid_1's l1: 0.616475\n[3500]\ttraining's l1: 0.437768\tvalid_1's l1: 0.612481\n[4000]\ttraining's l1: 0.41793\tvalid_1's l1: 0.609373\nDid not meet early stopping. Best iteration is:\n[4000]\ttraining's l1: 0.41793\tvalid_1's l1: 0.609373\nFold 3 started at Wed Apr 26 00:51:57 2023\nTraining until validation scores don't improve for 200 rounds.\n[500]\ttraining's l1: 0.61354\tvalid_1's l1: 0.650674\n[1000]\ttraining's l1: 0.571476\tvalid_1's l1: 0.638832\n[1500]\ttraining's l1: 0.538724\tvalid_1's l1: 0.632199\n[2000]\ttraining's l1: 0.50903\tvalid_1's l1: 0.625705\n[2500]\ttraining's l1: 0.483259\tvalid_1's l1: 0.621111\n[3000]\ttraining's l1: 0.459316\tvalid_1's l1: 0.616551\n[3500]\ttraining's l1: 0.437949\tvalid_1's l1: 0.61303\n[4000]\ttraining's l1: 0.418395\tvalid_1's l1: 0.609806\nDid not meet early stopping. Best iteration is:\n[4000]\ttraining's l1: 0.418395\tvalid_1's l1: 0.609806\nFold 4 started at Wed Apr 26 00:59:26 2023\nTraining until validation scores don't improve for 200 rounds.\n[500]\ttraining's l1: 0.613395\tvalid_1's l1: 0.650926\n[1000]\ttraining's l1: 0.572924\tvalid_1's l1: 0.640619\n[1500]\ttraining's l1: 0.539204\tvalid_1's l1: 0.633271\n[2000]\ttraining's l1: 0.509831\tvalid_1's l1: 0.627209\n[2500]\ttraining's l1: 0.483732\tvalid_1's l1: 0.622848\n[3000]\ttraining's l1: 0.459964\tvalid_1's l1: 0.618342\n[3500]\ttraining's l1: 0.438343\tvalid_1's l1: 0.614282\n[4000]\ttraining's l1: 0.418498\tvalid_1's l1: 0.610888\nDid not meet early stopping. Best iteration is:\n[4000]\ttraining's l1: 0.418498\tvalid_1's l1: 0.610888\nFold 5 started at Wed Apr 26 01:06:59 2023\nTraining until validation scores don't improve for 200 rounds.\n[500]\ttraining's l1: 0.612652\tvalid_1's l1: 0.651202\n[1000]\ttraining's l1: 0.572136\tvalid_1's l1: 0.640769\n[1500]\ttraining's l1: 0.538632\tvalid_1's l1: 0.633253\n[2000]\ttraining's l1: 0.509351\tvalid_1's l1: 0.627474\n[2500]\ttraining's l1: 0.483375\tvalid_1's l1: 0.622606\n[3000]\ttraining's l1: 0.459478\tvalid_1's l1: 0.618188\n[3500]\ttraining's l1: 0.437707\tvalid_1's l1: 0.614122\n[4000]\ttraining's l1: 0.417759\tvalid_1's l1: 0.610633\nDid not meet early stopping. Best iteration is:\n[4000]\ttraining's l1: 0.417759\tvalid_1's l1: 0.610633\nCV mean score: -0.4935, std: 0.0014.\nTraining of type 6\nFold 1 started at Wed Apr 26 01:14:28 2023\nTraining until validation scores don't improve for 200 rounds.\n[500]\ttraining's l1: 0.333698\tvalid_1's l1: 0.36673\n[1000]\ttraining's l1: 0.302259\tvalid_1's l1: 0.363333\n[1500]\ttraining's l1: 0.276203\tvalid_1's l1: 0.360484\n[2000]\ttraining's l1: 0.254038\tvalid_1's l1: 0.357907\n[2500]\ttraining's l1: 0.234419\tvalid_1's l1: 0.355359\n[3000]\ttraining's l1: 0.217109\tvalid_1's l1: 0.353119\n[3500]\ttraining's l1: 0.201662\tvalid_1's l1: 0.351118\n[4000]\ttraining's l1: 0.187795\tvalid_1's l1: 0.349604\nDid not meet early stopping. Best iteration is:\n[4000]\ttraining's l1: 0.187795\tvalid_1's l1: 0.349604\nFold 2 started at Wed Apr 26 01:18:48 2023\nTraining until validation scores don't improve for 200 rounds.\n[500]\ttraining's l1: 0.333887\tvalid_1's l1: 0.368773\n[1000]\ttraining's l1: 0.302282\tvalid_1's l1: 0.365123\n[1500]\ttraining's l1: 0.276322\tvalid_1's l1: 0.362138\n[2000]\ttraining's l1: 0.253884\tvalid_1's l1: 0.359349\n[2500]\ttraining's l1: 0.234376\tvalid_1's l1: 0.357169\n[3000]\ttraining's l1: 0.216966\tvalid_1's l1: 0.35501\n[3500]\ttraining's l1: 0.201654\tvalid_1's l1: 0.353088\n[4000]\ttraining's l1: 0.187722\tvalid_1's l1: 0.351218\nDid not meet early stopping. Best iteration is:\n[4000]\ttraining's l1: 0.187722\tvalid_1's l1: 0.351218\nFold 3 started at Wed Apr 26 01:22:58 2023\nTraining until validation scores don't improve for 200 rounds.\n[500]\ttraining's l1: 0.334091\tvalid_1's l1: 0.368731\n[1000]\ttraining's l1: 0.302151\tvalid_1's l1: 0.364091\n[1500]\ttraining's l1: 0.275829\tvalid_1's l1: 0.360834\n[2000]\ttraining's l1: 0.253646\tvalid_1's l1: 0.358379\n[2500]\ttraining's l1: 0.234279\tvalid_1's l1: 0.356346\n[3000]\ttraining's l1: 0.217112\tvalid_1's l1: 0.354309\n[3500]\ttraining's l1: 0.201548\tvalid_1's l1: 0.352443\n[4000]\ttraining's l1: 0.187808\tvalid_1's l1: 0.350925\nDid not meet early stopping. Best iteration is:\n[4000]\ttraining's l1: 0.187808\tvalid_1's l1: 0.350925\nFold 4 started at Wed Apr 26 01:27:08 2023\nTraining until validation scores don't improve for 200 rounds.\n[500]\ttraining's l1: 0.333802\tvalid_1's l1: 0.372795\n[1000]\ttraining's l1: 0.301806\tvalid_1's l1: 0.368273\n[1500]\ttraining's l1: 0.275577\tvalid_1's l1: 0.364793\n[2000]\ttraining's l1: 0.253113\tvalid_1's l1: 0.361984\n[2500]\ttraining's l1: 0.233741\tvalid_1's l1: 0.359678\n[3000]\ttraining's l1: 0.216346\tvalid_1's l1: 0.357312\n[3500]\ttraining's l1: 0.200819\tvalid_1's l1: 0.355423\n[4000]\ttraining's l1: 0.187091\tvalid_1's l1: 0.35379\nDid not meet early stopping. Best iteration is:\n[4000]\ttraining's l1: 0.187091\tvalid_1's l1: 0.35379\nFold 5 started at Wed Apr 26 01:31:21 2023\nTraining until validation scores don't improve for 200 rounds.\n[500]\ttraining's l1: 0.332869\tvalid_1's l1: 0.369655\n[1000]\ttraining's l1: 0.30124\tvalid_1's l1: 0.365754\n[1500]\ttraining's l1: 0.275149\tvalid_1's l1: 0.362631\n[2000]\ttraining's l1: 0.253058\tvalid_1's l1: 0.360081\n[2500]\ttraining's l1: 0.233715\tvalid_1's l1: 0.357683\n[3000]\ttraining's l1: 0.216358\tvalid_1's l1: 0.355361\n[3500]\ttraining's l1: 0.201079\tvalid_1's l1: 0.353527\n[4000]\ttraining's l1: 0.187358\tvalid_1's l1: 0.352243\nDid not meet early stopping. Best iteration is:\n[4000]\ttraining's l1: 0.187358\tvalid_1's l1: 0.352243\nCV mean score: -1.0454, std: 0.0040.\nTraining of type 5\nFold 1 started at Wed Apr 26 01:35:33 2023\nTraining until validation scores don't improve for 200 rounds.\n[500]\ttraining's l1: 0.66173\tvalid_1's l1: 0.690583\n[1000]\ttraining's l1: 0.625571\tvalid_1's l1: 0.678885\n[1500]\ttraining's l1: 0.595846\tvalid_1's l1: 0.671057\n[2000]\ttraining's l1: 0.569512\tvalid_1's l1: 0.664336\n[2500]\ttraining's l1: 0.545646\tvalid_1's l1: 0.658732\n[3000]\ttraining's l1: 0.524293\tvalid_1's l1: 0.654723\n[3500]\ttraining's l1: 0.504316\tvalid_1's l1: 0.650518\n[4000]\ttraining's l1: 0.485544\tvalid_1's l1: 0.646703\nDid not meet early stopping. Best iteration is:\n[4000]\ttraining's l1: 0.485544\tvalid_1's l1: 0.646703\nFold 2 started at Wed Apr 26 01:44:43 2023\nTraining until validation scores don't improve for 200 rounds.\n[500]\ttraining's l1: 0.663047\tvalid_1's l1: 0.693889\n[1000]\ttraining's l1: 0.625195\tvalid_1's l1: 0.680499\n[1500]\ttraining's l1: 0.595519\tvalid_1's l1: 0.672602\n[2000]\ttraining's l1: 0.569296\tvalid_1's l1: 0.665797\n[2500]\ttraining's l1: 0.545409\tvalid_1's l1: 0.660299\n[3000]\ttraining's l1: 0.523266\tvalid_1's l1: 0.65494\n[3500]\ttraining's l1: 0.50314\tvalid_1's l1: 0.650702\n[4000]\ttraining's l1: 0.48432\tvalid_1's l1: 0.646519\nDid not meet early stopping. Best iteration is:\n[4000]\ttraining's l1: 0.48432\tvalid_1's l1: 0.646519\nFold 3 started at Wed Apr 26 01:53:53 2023\nTraining until validation scores don't improve for 200 rounds.\n[500]\ttraining's l1: 0.662123\tvalid_1's l1: 0.691279\n[1000]\ttraining's l1: 0.62628\tvalid_1's l1: 0.679858\n[1500]\ttraining's l1: 0.595444\tvalid_1's l1: 0.670819\n[2000]\ttraining's l1: 0.569092\tvalid_1's l1: 0.664184\n[2500]\ttraining's l1: 0.545054\tvalid_1's l1: 0.658635\n[3000]\ttraining's l1: 0.52302\tvalid_1's l1: 0.653681\n[3500]\ttraining's l1: 0.502726\tvalid_1's l1: 0.649132\n[4000]\ttraining's l1: 0.484268\tvalid_1's l1: 0.645704\nDid not meet early stopping. Best iteration is:\n[4000]\ttraining's l1: 0.484268\tvalid_1's l1: 0.645704\nFold 4 started at Wed Apr 26 02:02:56 2023\nTraining until validation scores don't improve for 200 rounds.\n[500]\ttraining's l1: 0.662022\tvalid_1's l1: 0.69182\n[1000]\ttraining's l1: 0.625732\tvalid_1's l1: 0.680123\n[1500]\ttraining's l1: 0.59579\tvalid_1's l1: 0.671759\n[2000]\ttraining's l1: 0.569204\tvalid_1's l1: 0.664948\n[2500]\ttraining's l1: 0.545476\tvalid_1's l1: 0.659185\n[3000]\ttraining's l1: 0.523969\tvalid_1's l1: 0.654532\n[3500]\ttraining's l1: 0.5038\tvalid_1's l1: 0.650482\n[4000]\ttraining's l1: 0.484955\tvalid_1's l1: 0.646816\nDid not meet early stopping. Best iteration is:\n[4000]\ttraining's l1: 0.484955\tvalid_1's l1: 0.646816\nFold 5 started at Wed Apr 26 02:12:04 2023\nTraining until validation scores don't improve for 200 rounds.\n[500]\ttraining's l1: 0.662302\tvalid_1's l1: 0.693561\n[1000]\ttraining's l1: 0.625834\tvalid_1's l1: 0.681747\n[1500]\ttraining's l1: 0.596056\tvalid_1's l1: 0.673643\n[2000]\ttraining's l1: 0.56924\tvalid_1's l1: 0.666681\n[2500]\ttraining's l1: 0.545157\tvalid_1's l1: 0.661163\n[3000]\ttraining's l1: 0.52356\tvalid_1's l1: 0.656168\n[3500]\ttraining's l1: 0.503469\tvalid_1's l1: 0.65176\n[4000]\ttraining's l1: 0.484423\tvalid_1's l1: 0.647596\nDid not meet early stopping. Best iteration is:\n[4000]\ttraining's l1: 0.484423\tvalid_1's l1: 0.647596\nCV mean score: -0.4359, std: 0.0009.\nTraining of type 7\nFold 1 started at Wed Apr 26 02:21:09 2023\nTraining until validation scores don't improve for 200 rounds.\n[500]\ttraining's l1: 0.165238\tvalid_1's l1: 0.228383\n[1000]\ttraining's l1: 0.127857\tvalid_1's l1: 0.227143\n[1500]\ttraining's l1: 0.101424\tvalid_1's l1: 0.225749\n[2000]\ttraining's l1: 0.081791\tvalid_1's l1: 0.224373\n[2500]\ttraining's l1: 0.0669332\tvalid_1's l1: 0.223259\n[3000]\ttraining's l1: 0.055236\tvalid_1's l1: 0.222272\n[3500]\ttraining's l1: 0.0460833\tvalid_1's l1: 0.221429\n[4000]\ttraining's l1: 0.0386587\tvalid_1's l1: 0.22084\nDid not meet early stopping. Best iteration is:\n[4000]\ttraining's l1: 0.0386587\tvalid_1's l1: 0.22084\nFold 2 started at Wed Apr 26 02:22:50 2023\nTraining until validation scores don't improve for 200 rounds.\n[500]\ttraining's l1: 0.165823\tvalid_1's l1: 0.23157\n[1000]\ttraining's l1: 0.128428\tvalid_1's l1: 0.230415\n[1500]\ttraining's l1: 0.101928\tvalid_1's l1: 0.228625\n[2000]\ttraining's l1: 0.0822501\tvalid_1's l1: 0.227275\n[2500]\ttraining's l1: 0.0672978\tvalid_1's l1: 0.226344\n[3000]\ttraining's l1: 0.0556575\tvalid_1's l1: 0.225311\n[3500]\ttraining's l1: 0.0462847\tvalid_1's l1: 0.224572\n[4000]\ttraining's l1: 0.0388079\tvalid_1's l1: 0.223893\nDid not meet early stopping. Best iteration is:\n[4000]\ttraining's l1: 0.0388079\tvalid_1's l1: 0.223893\nFold 3 started at Wed Apr 26 02:24:30 2023\nTraining until validation scores don't improve for 200 rounds.\nEarly stopping, best iteration is:\n[171]\ttraining's l1: 0.201938\tvalid_1's l1: 0.22905\nFold 4 started at Wed Apr 26 02:24:39 2023\nTraining until validation scores don't improve for 200 rounds.\n[500]\ttraining's l1: 0.164611\tvalid_1's l1: 0.23128\n[1000]\ttraining's l1: 0.127365\tvalid_1's l1: 0.229947\n[1500]\ttraining's l1: 0.101056\tvalid_1's l1: 0.228507\n[2000]\ttraining's l1: 0.0814814\tvalid_1's l1: 0.227151\n[2500]\ttraining's l1: 0.0665905\tvalid_1's l1: 0.226088\n[3000]\ttraining's l1: 0.0550611\tvalid_1's l1: 0.225229\n[3500]\ttraining's l1: 0.0458951\tvalid_1's l1: 0.22442\n[4000]\ttraining's l1: 0.0385066\tvalid_1's l1: 0.223731\nDid not meet early stopping. Best iteration is:\n[4000]\ttraining's l1: 0.0385066\tvalid_1's l1: 0.223731\nFold 5 started at Wed Apr 26 02:26:19 2023\nTraining until validation scores don't improve for 200 rounds.\n[500]\ttraining's l1: 0.165273\tvalid_1's l1: 0.228489\n[1000]\ttraining's l1: 0.127535\tvalid_1's l1: 0.227325\n[1500]\ttraining's l1: 0.100985\tvalid_1's l1: 0.225795\n[2000]\ttraining's l1: 0.081491\tvalid_1's l1: 0.224512\n[2500]\ttraining's l1: 0.066635\tvalid_1's l1: 0.223484\n[3000]\ttraining's l1: 0.0550687\tvalid_1's l1: 0.222652\n[3500]\ttraining's l1: 0.0458925\tvalid_1's l1: 0.221828\n[4000]\ttraining's l1: 0.0385522\tvalid_1's l1: 0.221259\nDid not meet early stopping. Best iteration is:\n[4000]\ttraining's l1: 0.0385522\tvalid_1's l1: 0.221259\nCV mean score: -1.4973, std: 0.0130.\n","output_type":"stream"}]},{"cell_type":"markdown","source":"\n","metadata":{}},{"cell_type":"markdown","source":"<a id=\"id7\"></a> <br> \n# **7. Submittion** ","metadata":{}},{"cell_type":"code","source":"#Training models for type\nsub['scalar_coupling_constant'] = X_short_test['prediction']\nsub.to_csv('submission_type.csv', index=False)\nsub.head()\n","metadata":{"execution":{"iopub.status.busy":"2023-04-26T02:28:00.515001Z","iopub.execute_input":"2023-04-26T02:28:00.515225Z","iopub.status.idle":"2023-04-26T02:28:10.198591Z","shell.execute_reply.started":"2023-04-26T02:28:00.515188Z","shell.execute_reply":"2023-04-26T02:28:10.197713Z"},"trusted":true},"execution_count":33,"outputs":[{"execution_count":33,"output_type":"execute_result","data":{"text/plain":"        id  scalar_coupling_constant\n0  4659076         9.973890770701788\n1  4659077       182.761281907407948\n2  4659078         3.936335273494435\n3  4659079       184.086918396487533\n4  4659080         7.938796945554417","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>scalar_coupling_constant</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>4659076</td>\n      <td>9.973890770701788</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>4659077</td>\n      <td>182.761281907407948</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>4659078</td>\n      <td>3.936335273494435</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4659079</td>\n      <td>184.086918396487533</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4659080</td>\n      <td>7.938796945554417</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"<a id=\"ref\"></a> <br> \n# **8. References** \n\n[1] OOF Model: https://www.kaggle.com/adarshchavakula/out-of-fold-oof-model-cross-validation<br>\n[2] Using Meta Features: https://www.kaggle.com/artgor/using-meta-features-to-improve-model<br>\n[3] Lot of Features: https://towardsdatascience.com/understanding-feature-engineering-part-1-continuous-numeric-data-da4e47099a7b <br>\n[4] Angle Feature: https://www.kaggle.com/kmat2019/effective-feature <br>\n[5] Recovering bonds from structure: https://www.kaggle.com/aekoch95/bonds-from-structure-data <br>\n\n<h3 style=\"color:red\">If this Kernel Helps You! Please UP VOTE! üòÅ</h3>","metadata":{}}]}